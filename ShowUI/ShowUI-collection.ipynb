{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "574c45b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "import wandb\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from PIL import Image, ImageDraw\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from transformers import BitsAndBytesConfig, AutoProcessor, get_linear_schedule_with_warmup, get_constant_schedule_with_warmup\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from model.utils import find_target_linear_names\n",
    "from main.trainer import train\n",
    "from main.eval_aitw import validate_aitw\n",
    "from main.eval_mind2web import validate_mind2web\n",
    "from main.eval_screenspot import validate_screenspot\n",
    "from main.evaluator import validate as validate_default\n",
    "from data.dataset import HybridDataset, collate_fn\n",
    "from utils.utils import save_args_to_json, create_log_dir\n",
    "from merge_weight import load_sharded_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f11f347",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    # wandb配置参数\n",
    "    \"wandb_key\": \"7dd9f7e0d1d48f0b0296d469ce4b6365e615094d\", # 修改为你的wandb API key\n",
    "    \"local_rank\": 0, # 本地rank，0表示单机单卡训练\n",
    "\n",
    "    # 需要修改的路径参数\n",
    "    \"model_path\": \"D:/Project/showui-2b\", # 修改为你的基模型路径\n",
    "    \"train_dataset\": \"showui-desktop\", # 修改为你的训练数据集路径\n",
    "    \"train_json\": \"metadata\", # 修改为你的训练数据集标注文件名\n",
    "    \"val_dataset\": \"showui-desktop\", # 修改为你的验证数据集路径\n",
    "    \"val_json\": \"metadata\", # 修改为你的验证数据集标注文件名\n",
    "    \"dataset_dir\": \"D:/Project/my_dataset\", # 修改为你的数据集目录路径\n",
    "    \"exp_dir\": \"D:/Project/logs/debug/2025-06-22_19-28-54\", # 请修改为你的LoRA权重保存路径\n",
    "\n",
    "    # 模型配置参数\n",
    "    \"model_id\": \"local_ShowUI-2B\", # 模型ID\n",
    "    \"version\": \"showlab/ShowUI-2B\", # 模型版本路径\n",
    "    \"min_visual_tokens\": 256, # 最小视觉token数量\n",
    "    \"max_visual_tokens\": 1344, # 最大视觉token数量\n",
    "    \"model_max_length\": 8192, # 模型最大长度，8192表示支持长文本输入\n",
    "    \"max_new_tokens\": 128, # 最大新生成token数量\n",
    "\n",
    "    # ui图配置参数\n",
    "    \"uigraph_train\": True, # 启用ui图训练\n",
    "    \"uigraph_test\": False, # 启用ui图测试\n",
    "    \"uigraph_diff\": 1, # UI图差异阈值，1表示仅保留有差异的patch\n",
    "    \"uigraph_rand\": False, # 是否随机选择patch进行训练，False表示均匀选择\n",
    "    \"uimask_pre\": True, # 是否预处理UI图，True表示预处理\n",
    "    \"uimask_ratio\": 0.5, # UI图掩码比例，0.5表示50%的UI图被掩码\n",
    "    \"uimask_rand\": False, # 是否随机掩码UI图，False表示均匀掩码\n",
    "    \n",
    "    \"precision\": \"bf16\", # 训练精度，支持\"fp16\", \"bf16\", \"fp32\"\n",
    "    \n",
    "    # 语言和视觉层跳过参数\n",
    "    \"lm_skip_ratio\": 0.5, # 语言层跳过比例，0.5表示跳过50%的语言层\n",
    "    \"lm_skip_layer\": '[1,28,0]', # 语言层跳过层数，e.g., [1,28,0]表示跳过第1层和第28层\n",
    "    \"vis_skip_ratio\": 0.5, # 视觉层跳过比例，0.5表示跳过50%的视觉层\n",
    "    \"vis_skip_layer\": '[1,32,0]', # 视觉层跳过层数，e.g., [1,32,0]表示跳过第1层和第32层\n",
    "    \"attn_imple\": \"sdpa\", # 注意力实现方式，支持\"flash_attention_2\", \"sdpa\", \"eager\"\n",
    "    \n",
    "    # LoRA微调配置参数\n",
    "    \"use_qlora\": False, # 是否使用QLoRA进行训练\n",
    "    \"lora_r\": 32, # LoRA的r值，表示低秩矩阵的秩\n",
    "    \"lora_alpha\": 64, # LoRA的alpha值，表示缩放因子\n",
    "    \"lora_dropout\": 0.05, # LoRA的dropout率\n",
    "    \"lora_target_modules\": [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"], # LoRA目标模块，支持\"qkv_proj\", \"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"\n",
    "    \"tune_visual_encoder\": False, # 是否微调视觉编码器\n",
    "    \"freeze_lm_embed\": False, # 是否冻结语言模型嵌入层\n",
    "    \"tune_visual_encoder_projector\": False, # 是否微调视觉编码器投影层\n",
    "    \n",
    "    # 梯度检查点配置参数\n",
    "    \"gradient_checkpointing\": True, # 是否启用梯度检查点\n",
    "\n",
    "\n",
    "    # 数据集配置参数\n",
    "    \"train_ratio\": \"1.0\", # 训练数据比例，可以是0到1之间的浮点数\n",
    "    \"val_ratio\": \"1.0\", # 验证数据比例，可以是0到1之间的浮点数\n",
    "    \"uniform_sample\": False, # 是否使用均匀采样进行训练数据采样\n",
    "    \"random_sample\": False, # 是否使用随机采样进行训练数据采样\n",
    "    \"record_sample\": False, # 是否记录采样数据\n",
    "\n",
    "    # 训练配置参数\n",
    "    \"log_base_dir\": \"D:/Project/logs\", # 日志基础目录\n",
    "    \"exp_id\": \"debug\", # 实验ID，用于区分不同实验\n",
    "    \"lr\": 1e-5, # 学习率\n",
    "    \"beta1\": 0.9, # 优化器的Beta1参数\n",
    "    \"beta2\": 0.999, # 优化器的Beta2参数\n",
    "    \"epochs\": 10, # 训练轮数\n",
    "    \"steps_per_epoch\": 100, # 每个epoch的训练步数\n",
    "    \"warmup_steps\": 30, # 预热步数\n",
    "    \"batch_size\": 1, # 训练批次大小\n",
    "    \"grad_accumulation_steps\": 2, # 梯度累积步数\n",
    "    \"val_batch_size\": 1, # 验证批次大小\n",
    "    \"workers\": 0, # 数据加载器工作线程数\n",
    "\n",
    "    # Grounding setting\n",
    "    \"num_turn\": 100, # 交互轮数\n",
    "    \"shuffle_image_token\": False, # 随机打乱图像token顺序\n",
    "    \"uniform_prompt\": True, # 使用统一的提示词\n",
    "    \"text2point\": 1.0, # 文本到点的任务采样比例\n",
    "    \"text2bbox\": 0.0, # 文本到边界框的任务采样比例\n",
    "    \"point2text\": 0.0, # 点到文本的任务采样比例\n",
    "    \"bbox2text\": 0.0, # 边界框到文本的任务采样比例\n",
    "    \"crop_min\": 0.5 , # \n",
    "    \"crop_max\": 1.5, # \n",
    "    \"xy_int\": False, # 是否将坐标转换为整数\n",
    "\n",
    "    # Navigation setting\n",
    "    \"num_history\": 4, # 历史交互轮数\n",
    "    \"interleaved_history\": 'tttt', # 视觉-动作交互设置，选项=['tttt', 'vvvv', 'vtvt', 'tvtv', 'vvtt', 'ttvv']\n",
    "    \"skip_readme_train\": False, # 是否跳过README训练数据\n",
    "    \"skip_readme_test\": False, # 是否跳过README测试数据\n",
    "\n",
    "    # 模型检测点和评估配置参数\n",
    "    \"eval_only\": False, # 是否仅进行评估，不进行训练\n",
    "    \"start_epoch\": 0, # 开始训练的epoch\n",
    "    \"no_eval\": False, # 是否跳过评估\n",
    "    \"debug\": False, # debug模式，True表示启用，不保存模型日志\n",
    "    \"print_freq\": 1, # 输出频率，表示每隔多少步输出一次日志\n",
    "\n",
    "\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f351fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "# 如果args是字典，将其转换为SimpleNamespace对象\n",
    "if isinstance(args, dict):\n",
    "    args = SimpleNamespace(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18458e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型主函数\n",
    "def ShowUItrain(args):\n",
    "\n",
    "    args.global_rank = int(os.environ.get(\"RANK\", 0))\n",
    "    args.local_rank = int(os.environ.get(\"LOCAL_RANK\", 0))\n",
    "    args.world_size = int(os.environ.get(\"WORLD_SIZE\", 1))\n",
    "\n",
    "\n",
    "    if args.attn_imple in [\"eager\", \"sdpa\"]:\n",
    "        # suggested by https://github.com/Lightning-AI/litgpt/issues/327\n",
    "        torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "        torch.backends.cuda.enable_flash_sdp(False)\n",
    "\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "    args.distributed = args.world_size > 1\n",
    "\n",
    "\n",
    "    args.log_dir = os.path.join(args.log_base_dir, args.exp_id, timestamp)\n",
    "    args.tmp_dir = os.path.join(args.log_dir, \"tmp\")\n",
    "\n",
    "    # must provide wandb-key\n",
    "    assert args.wandb_key is not None\n",
    "    wandb.login(key=args.wandb_key)\n",
    "\n",
    "\n",
    "    writer = None  # TensorBoard writer, if needed, can be initialized later\n",
    "    os.makedirs(args.log_dir, exist_ok=True)\n",
    "    os.makedirs(args.tmp_dir, exist_ok=True)\n",
    "    save_args_to_json(args, os.path.join(args.log_dir, \"args.json\"))  # 保存参数\n",
    "    if not args.debug:\n",
    "        # 创建TensorBoard日志目录\n",
    "        writer = SummaryWriter(os.path.join(args.log_dir, \"tensorboard\"))\n",
    "        # 初始化wandb\n",
    "        wandb.init(\n",
    "            project=\"ShowUI\",\n",
    "            group=args.exp_id,\n",
    "            name=f'{args.exp_id}_{timestamp}',\n",
    "            config=args,\n",
    "            dir=args.log_dir,\n",
    "        )\n",
    "    print(f\"Start Job: {args.exp_id}\")\n",
    "\n",
    "    # 创建处理器\n",
    "\n",
    "    from model.showui.processing_showui import ShowUIProcessor\n",
    "\n",
    "    processor = ShowUIProcessor.from_pretrained(args.model_path,\n",
    "                                                min_pixels=args.min_visual_tokens *28*28,\n",
    "                                                max_pixels=args.max_visual_tokens *28*28,\n",
    "                                                model_max_length=args.model_max_length,\n",
    "                                                uigraph_train=args.uigraph_train, uigraph_test=args.uigraph_test,\n",
    "                                                uigraph_diff=args.uigraph_diff,  uigraph_rand=args.uigraph_rand,\n",
    "                                                uimask_pre=args.uimask_pre, uimask_ratio=args.uimask_ratio, uimask_rand=args.uimask_rand,\n",
    "                                                size = {\"shortest_edge\": 3136, \"longest_edge\": 1003520}\n",
    "                                              )\n",
    "    \n",
    "    CHAT_TEMPLATE = \"{% set image_count = namespace(value=0) %}{% set video_count = namespace(value=0) %}{% for message in messages %}<|im_start|>{{ message['role'] }}\\n{% if message['content'] is string %}{{ message['content'] }}<|im_end|>\\n{% else %}{% for content in message['content'] %}{% if content['type'] == 'image' or 'image' in content or 'image_url' in content %}{% set image_count.value = image_count.value + 1 %}{% if add_vision_id %}Picture {{ image_count.value }}: {% endif %}<|vision_start|><|image_pad|><|vision_end|>{% elif content['type'] == 'video' or 'video' in content %}{% set video_count.value = video_count.value + 1 %}{% if add_vision_id %}Video {{ video_count.value }}: {% endif %}<|vision_start|><|video_pad|><|vision_end|>{% elif 'text' in content %}{{ content['text'] }}{% endif %}{% endfor %}<|im_end|>\\n{% endif %}{% endfor %}{% if add_generation_prompt %}<|im_start|>assistant\\n{% endif %}\"\n",
    "    processor.chat_template = CHAT_TEMPLATE\n",
    "    processor.tokenizer.chat_template = CHAT_TEMPLATE\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 创建模型\n",
    "    torch_dtype = torch.float32\n",
    "    if args.precision == \"bf16\":\n",
    "        torch_dtype = torch.bfloat16\n",
    "    elif args.precision == \"fp16\":\n",
    "        torch_dtype = torch.half\n",
    "\n",
    "    model_path = args.model_path\n",
    "    \n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "                    load_in_4bit=True,\n",
    "                    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                    bnb_4bit_use_double_quant=True,\n",
    "                    bnb_4bit_quant_type=\"nf4\",\n",
    "                    llm_int8_skip_modules=[\"img_projection\"],\n",
    "                ) if args.use_qlora else None # 仅在使用QLoRA时才需要配置\n",
    "    \n",
    "    from model.utils import parse_layer_type\n",
    "    from model.showui.modeling_showui import ShowUIForConditionalGeneration\n",
    "\n",
    "    lm_qwen_layer = 28\n",
    "    vis_qwen_layer = 32\n",
    "    lm_skip_layer = parse_layer_type(args.lm_skip_layer, lm_qwen_layer)\n",
    "    vis_skip_layer = parse_layer_type(args.vis_skip_layer, vis_qwen_layer)\n",
    "\n",
    "    model = ShowUIForConditionalGeneration.from_pretrained(\n",
    "        model_path,\n",
    "        torch_dtype=torch_dtype, # 模型精度\n",
    "        low_cpu_mem_usage=True, # 低内存使用模式\n",
    "        _attn_implementation=args.attn_imple, # 注意力实现方式\n",
    "        # quantization_config=bnb_config, # 量化配置\n",
    "        device_map=\"cuda\", # 自动设备映射\n",
    "        lm_skip_layer=lm_skip_layer, # 跳过语言层\n",
    "        lm_skip_ratio=args.lm_skip_ratio, # 跳过语言层比例\n",
    "        tie_word_embeddings=False, # 是否共享词嵌入\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # 加载模型检测点\n",
    "    # if args.version != args.model_id:\n",
    "    #     state_dict = torch.load(args.version, map_location=\"cpu\")\n",
    "    #     model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    model.config.use_cache = False # 禁用缓存以节省内存\n",
    "\n",
    "    # 在评估模式下，不需要加载LoRA\n",
    "    if args.eval_only:\n",
    "        print(\"evaluation mode, thus set the `lora_r' as zero.\")\n",
    "        args.lora_r = 0\n",
    "    if not args.eval_only and args.use_qlora:\n",
    "        model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "    # 配置LoRA\n",
    "    lora_r = args.lora_r\n",
    "    if lora_r > 0:\n",
    "        lora_alpha = args.lora_alpha\n",
    "        lora_dropout = args.lora_dropout\n",
    "        exclude_module = [\"visual\"] if not args.tune_visual_encoder else []\n",
    "        exclude_module += [\"lm_head\"] if args.freeze_lm_embed else exclude_module\n",
    "        lora_target_modules = find_target_linear_names(model, lora_namespan_exclude=exclude_module)\n",
    "\n",
    "        lora_config = LoraConfig(\n",
    "            r=lora_r,\n",
    "            lora_alpha=lora_alpha,\n",
    "            target_modules=lora_target_modules,\n",
    "            lora_dropout=lora_dropout,\n",
    "            bias=\"none\",\n",
    "            task_type=\"CAUSAL_LM\",\n",
    "        )\n",
    "        model = get_peft_model(model, lora_config)\n",
    "        # model.print_trainable_parameters()\n",
    "\n",
    "        # 如果使用LoRA，则原始模型被包装2次\n",
    "        # 一次是peft的get_peft_model包装，一次是ShowUIForConditionalGeneration的包装\n",
    "        model_child = model.model.model # 获取原始模型，疑似不可使用base_model方法\n",
    "    else:\n",
    "        # 如果不使用LoRA，则原始模型只被ShowUIForConditionalGeneration包装\n",
    "        model_child = model.model\n",
    "    \n",
    "    # 梯度检查点，降低显存使用\n",
    "    if args.gradient_checkpointing:\n",
    "        model.enable_input_require_grads()\n",
    "        model.gradient_checkpointing_enable()\n",
    "        \n",
    "    \n",
    "    if not args.tune_visual_encoder:\n",
    "        # 冻结视觉编码器\n",
    "        if args.lora_r > 0:\n",
    "            for p in model.base_model.model.visual.parameters():\n",
    "                p.requires_grad = False\n",
    "        elif args.lora_r == 0:\n",
    "            for p in model.visual.parameters():\n",
    "                p.requires_grad = False\n",
    "        \n",
    "    if args.tune_visual_encoder_projector:\n",
    "        for k, p in model.named_parameters():\n",
    "            if 'visual.merger' in k:\n",
    "                p.requires_grad = True\n",
    "    \n",
    "    if args.freeze_lm_embed:\n",
    "        if args.lora_r > 0:\n",
    "            for p in model_child.embed_tokens.parameters():\n",
    "                p.requires_grad = False\n",
    "        elif args.lora_r == 0:\n",
    "            for p in model_child.embed_tokens.parameters():\n",
    "                p.requires_grad = False\n",
    "    \n",
    "    # 检查可训练参数\n",
    "    list_of_params_to_optimize = []\n",
    "    for n, p in model.named_parameters():\n",
    "        if p.requires_grad:\n",
    "            # print(\"[Name]\", n, \" [Shape]\", p.shape)\n",
    "            list_of_params_to_optimize.append(p)\n",
    "    \n",
    "    # 创建数据集\n",
    "    args.samples_per_epoch = args.batch_size    \\\n",
    "                    * args.grad_accumulation_steps  \\\n",
    "                    * args.steps_per_epoch\n",
    "\n",
    "    train_dataset = HybridDataset(\n",
    "        processor,\n",
    "        inference=False,  # 仅用于训练\n",
    "        args=args,\n",
    "    )\n",
    "    \n",
    "    val_dataset = HybridDataset(\n",
    "        processor,\n",
    "        inference=True,  # 仅用于验证\n",
    "        args=args,\n",
    "    )\n",
    "\n",
    "    if args.val_dataset == \"mind2web\":\n",
    "        validate = validate_mind2web\n",
    "    elif args.val_dataset == \"screenspot\":\n",
    "        validate = validate_screenspot\n",
    "    elif args.val_dataset == \"aitw\":\n",
    "        validate = validate_aitw\n",
    "    else:\n",
    "        validate = validate_default\n",
    "\n",
    "    if not args.random_sample:\n",
    "        args.steps_per_epoch = len(train_dataset) // (args.batch_size * args.world_size)\n",
    "    print(\"step for epoch: \", args.steps_per_epoch)\n",
    "    # deepspeed参数（待完成）\n",
    "    # 如果使用DeepSpeed，参考https://github.com/showlab/ShowUI/blob/main/train.py\n",
    "\n",
    "    # LoRA微调\n",
    "    if lora_r > 0:\n",
    "        print(\"LoRA training, r: {}, alpha: {}, dropout: {}\".format(\n",
    "            lora_r, lora_alpha, lora_dropout))\n",
    "        # 创建优化器\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            list_of_params_to_optimize,\n",
    "            lr=args.lr,\n",
    "            betas=(args.beta1, args.beta2),\n",
    "            weight_decay=0.0,\n",
    "            )\n",
    "\n",
    "        \n",
    "\n",
    "        # DeepSpeed 用的是 WarmupDecayLR，PyTorch 没有内置这个，但可以用类似的调度器\n",
    "        total_steps = args.epochs * args.steps_per_epoch\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=args.warmup_steps,\n",
    "            num_training_steps=total_steps,\n",
    "        )\n",
    "\n",
    "        # 创建数据加载器\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=args.batch_size,\n",
    "            shuffle=False,\n",
    "            collate_fn=partial(collate_fn, processor=processor),\n",
    "            num_workers=args.workers,  # 根据你的CPU核心数调整\n",
    "        )\n",
    "        \n",
    "\n",
    "        # 模型引擎\n",
    "        model_engine = model\n",
    "        model_engine = model_engine.to(\"cuda\")\n",
    "\n",
    "        \n",
    "\n",
    "    # 如果不使用LoRA微调\n",
    "    # 暂时一样，但是方便后续扩展\n",
    "    elif lora_r == 0 and not args.eval_only:\n",
    "        # 创建优化器\n",
    "        print(\"No LoRA, using full model training\")\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            list_of_params_to_optimize,\n",
    "            lr=args.lr,\n",
    "            betas=(args.beta1, args.beta2),\n",
    "            weight_decay=0.0,\n",
    "            )\n",
    "\n",
    "        # DeepSpeed 用的是 WarmupDecayLR，PyTorch 没有内置这个，但可以用类似的调度器\n",
    "        total_steps = args.epochs * args.steps_per_epoch\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=args.warmup_steps,\n",
    "            num_training_steps=total_steps,\n",
    "        )\n",
    "\n",
    "        # 创建数据加载器\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=args.batch_size,\n",
    "            shuffle=False,\n",
    "            collate_fn=partial(collate_fn, processor=processor),\n",
    "            num_workers=args.workers,  # 根据你的CPU核心数调整\n",
    "        )\n",
    "\n",
    "        # 模型引擎\n",
    "        model_engine = model\n",
    "        model_engine = model_engine.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "    # 仅评估模式\n",
    "    elif args.eval_only:\n",
    "        print(\"Evaluation mode, no training\")\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False \n",
    "        model_engine = model\n",
    "    else:\n",
    "        raise ValueError(\"Invalid setting\")\n",
    "    \n",
    "\n",
    "    # 断点加载（待完成）\n",
    "\n",
    "    # 验证集\n",
    "    if val_dataset is not None:\n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=args.val_batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=args.workers,\n",
    "            pin_memory=False,\n",
    "            sampler= None,  # 若分布式训练，此处参考https://github.com/showlab/ShowUI/blob/main/train.py\n",
    "            collate_fn=partial(collate_fn, processor=processor)\n",
    "        )\n",
    "    else:\n",
    "        val_loader = None\n",
    "    \n",
    "    if args.eval_only:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model_engine = model_engine.to(device)\n",
    "        validate(val_loader, model_engine, processor, 0, 0, writer, args)\n",
    "        exit()\n",
    "\n",
    "    train_iter = iter(train_loader)\n",
    "    best_score = 0.0\n",
    "    # args.start_epoch 是为了支持断点恢复训练\n",
    "    print(\"开始训练\")\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        # train for one epoch\n",
    "        train_iter, global_step = train(\n",
    "            train_loader,\n",
    "            model_engine,\n",
    "            optimizer,\n",
    "            epoch,\n",
    "            scheduler,\n",
    "            writer,\n",
    "            train_iter,\n",
    "            args,\n",
    "        )\n",
    "\n",
    "        if args.no_eval == False and val_loader is not None:\n",
    "            score = validate(\n",
    "                val_loader,\n",
    "                model_engine,\n",
    "                processor,\n",
    "                epoch,\n",
    "                global_step,\n",
    "                writer,\n",
    "                args,\n",
    "            )\n",
    "            is_best = score > best_score\n",
    "            best_score = max(score, best_score)\n",
    "        else:\n",
    "            is_best = True\n",
    "            score = 0.0\n",
    "        \n",
    "        if args.no_eval or is_best:\n",
    "            save_dir = os.path.join(args.log_dir,\"ckpt_model\")\n",
    "            \n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            torch.save(\n",
    "                {\"epoch\": epoch},\n",
    "                os.path.join(\n",
    "                    save_dir,\n",
    "                    \"meta_log_epo{:.0f}_score{:.2f}.pth\".format(\n",
    "                            epoch, best_score\n",
    "                        ),\n",
    "                ),\n",
    "            )\n",
    "            # if args.distributed:\n",
    "            #     # 确保所有进程都完成保存\n",
    "            #     torch.distributed.barrier()\n",
    "            try:\n",
    "                torch.save(\n",
    "                    model_engine.state_dict(),\n",
    "                    os.path.join(\n",
    "                        save_dir,\n",
    "                        \"model_epo{:.0f}_score{:.2f}.pth\".format(\n",
    "                            epoch, best_score\n",
    "                        ),\n",
    "                    ),\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(\"Failed to save checkpoint (): \", e)\n",
    "    \n",
    "    \n",
    "    if args.global_rank == 0:\n",
    "        if not args.debug:\n",
    "            wandb.finish()\n",
    "            writer.close()\n",
    "\n",
    "# 合并LoRA权重和原始模型\n",
    "def ShowUImerge(args):\n",
    "    json_url = os.path.join(args.exp_dir, \"args.json\")\n",
    "    with open(json_url,'r') as f:\n",
    "        json_args = json.load(f)\n",
    "    for key, value in json_args.items():\n",
    "        setattr(args, key, value)\n",
    "    \n",
    "    args.save_path = args.exp_dir +\"/ckpt_model/merged_model\"\n",
    "    args.weight_url = args.exp_dir +\"/ckpt_model/adapter_model.safetensors\"\n",
    "\n",
    "    torch_dtype = torch.float32\n",
    "    if args.precision == \"bf16\":\n",
    "        torch_dtype = torch.bfloat16\n",
    "    elif args.precision == \"fp16\":\n",
    "        torch_dtype = torch.half\n",
    "    \n",
    "    from model.showui.processing_showui import ShowUIProcessor\n",
    "\n",
    "    processor = ShowUIProcessor.from_pretrained(args.model_path,\n",
    "                                                min_pixels=args.min_visual_tokens *28*28,\n",
    "                                                max_pixels=args.max_visual_tokens *28*28,\n",
    "                                                model_max_length=args.model_max_length,\n",
    "                                                uigraph_train=args.uigraph_train, uigraph_test=args.uigraph_test,\n",
    "                                                uigraph_diff=args.uigraph_diff,  uigraph_rand=args.uigraph_rand,\n",
    "                                                uimask_pre=args.uimask_pre, uimask_ratio=args.uimask_ratio, uimask_rand=args.uimask_rand,\n",
    "                                                size = {\"shortest_edge\": 3136, \"longest_edge\": 1003520}\n",
    "                                              )\n",
    "    \n",
    "    from model.utils import parse_layer_type\n",
    "    from model.showui.modeling_showui import ShowUIForConditionalGeneration\n",
    "\n",
    "    lm_qwen_layer = 28\n",
    "    vis_qwen_layer = 32\n",
    "    lm_skip_layer = parse_layer_type(args.lm_skip_layer, lm_qwen_layer)\n",
    "    vis_skip_layer = parse_layer_type(args.vis_skip_layer, vis_qwen_layer)\n",
    "\n",
    "    model = ShowUIForConditionalGeneration.from_pretrained(\n",
    "        args.model_path,\n",
    "        torch_dtype=torch_dtype, # 模型精度\n",
    "        low_cpu_mem_usage=True, # 低内存使用模式\n",
    "        _attn_implementation=args.attn_imple, # 注意力实现方式\n",
    "        # quantization_config=bnb_config, # 量化配置\n",
    "        device_map=\"cuda\", # 自动设备映射\n",
    "        lm_skip_layer=lm_skip_layer, # 跳过语言层\n",
    "        lm_skip_ratio=args.lm_skip_ratio, # 跳过语言层比例\n",
    "    )\n",
    "    \n",
    "    model.config.use_cache = False\n",
    "    model.config.tokenizer_model_max_length = processor.tokenizer.model_max_length\n",
    "\n",
    "    lora_r = args.lora_r\n",
    "    if lora_r > 0:\n",
    "        lora_alpha = args.lora_alpha\n",
    "        lora_dropout = args.lora_dropout\n",
    "        lora_target_modules = find_target_linear_names(model, lora_namespan_exclude=[\"visual\"])\n",
    "        lora_config = LoraConfig(\n",
    "            r=lora_r,\n",
    "            lora_alpha=lora_alpha,\n",
    "            target_modules=lora_target_modules,\n",
    "            lora_dropout=lora_dropout,\n",
    "            bias=\"none\",\n",
    "            task_type=\"CAUSAL_LM\",\n",
    "        )\n",
    "        model = get_peft_model(model, lora_config)\n",
    "        \n",
    "        model.print_trainable_parameters()\n",
    "        \n",
    "        print(\"Loading LoRA weights from {}\".format(args.weight_url))\n",
    "        state_dict = load_sharded_weights(args.weight_url, device_map=\"cuda\")\n",
    "        missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
    "        print(\"Loaded weights with {len(missing_keys)} missing keys and {len(unexpected_keys)} unexpected keys\")\n",
    "        \n",
    "        # 合并LoRA权重\n",
    "        print(\"Merging LoRA weights...\")\n",
    "        model = model.merge_and_unload()\n",
    "\n",
    "        # 将合并后的模型权重保存到指定路径\n",
    "        print(\"Saving merged model to {args.save_path}\")\n",
    "        model.save_pretrained(\n",
    "            args.save_path,\n",
    "            max_shard_size=\"10GB\",  # 分片大小\n",
    "            safe_serialization=True,  # 安全序列化\n",
    "        )\n",
    "        processor.save_pretrained(args.save_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503774e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\AMATEUR\\_netrc\n",
      "wandb: Currently logged in as: aa1687159592 (aa1687159592-) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>D:/Project/logs\\debug\\2025-06-23_01-02-20\\wandb\\run-20250623_010222-68f4yu2j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aa1687159592-/ShowUI/runs/68f4yu2j' target=\"_blank\">debug_2025-06-23_01-02-20</a></strong> to <a href='https://wandb.ai/aa1687159592-/ShowUI' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aa1687159592-/ShowUI' target=\"_blank\">https://wandb.ai/aa1687159592-/ShowUI</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aa1687159592-/ShowUI/runs/68f4yu2j' target=\"_blank\">https://wandb.ai/aa1687159592-/ShowUI/runs/68f4yu2j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Job: debug\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:model.showui.modeling_showui:`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 197 lora modules: ['model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'lm_head']\n",
      "Dataset: showui-desktop; Split: metadata; # samples: 100\n",
      "Loading 1 Training Datasets\n",
      "Dataset: showui-desktop; Split: metadata; # samples: 100\n",
      "Loading 1 Validation Datasets\n",
      "step for epoch:  100\n",
      "LoRA training, r: 32, alpha: 64, dropout: 0.05\n",
      "开始训练\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 0.0\n",
      "Epoch: [0][  1/100]\tBatch time (s)  1.243 ( 1.243)\tLoss 0.3138 (0.3106)\tIter time (s)  0.621 ( 0.621)\tEpoch time (h)  0.017 ( 0.017)\tRemain time (h)  0.017 ( 0.017)\tSeq Len 543.000 (543.000)\tCtx Len 147.000 (147.000)\tVis Len 396.000 (396.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 3.3333333333333335e-07\n",
      "Epoch: [0][  2/100]\tBatch time (s)  1.216 ( 1.216)\tLoss 0.2515 (0.2051)\tIter time (s)  0.608 ( 0.608)\tEpoch time (h)  0.017 ( 0.017)\tRemain time (h)  0.017 ( 0.017)\tSeq Len 515.000 (515.000)\tCtx Len 147.000 (147.000)\tVis Len 368.000 (368.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 6.666666666666667e-07\n",
      "Epoch: [0][  3/100]\tBatch time (s)  1.247 ( 1.247)\tLoss 0.2672 (0.2969)\tIter time (s)  0.624 ( 0.624)\tEpoch time (h)  0.017 ( 0.017)\tRemain time (h)  0.017 ( 0.017)\tSeq Len 675.000 (675.000)\tCtx Len 147.000 (147.000)\tVis Len 528.000 (528.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 1.0000000000000002e-06\n",
      "Epoch: [0][  4/100]\tBatch time (s)  0.934 ( 0.934)\tLoss 0.3339 (0.2737)\tIter time (s)  0.467 ( 0.467)\tEpoch time (h)  0.013 ( 0.013)\tRemain time (h)  0.012 ( 0.012)\tSeq Len 511.000 (511.000)\tCtx Len 143.000 (143.000)\tVis Len 368.000 (368.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 1.3333333333333334e-06\n",
      "Epoch: [0][  5/100]\tBatch time (s)  1.841 ( 1.841)\tLoss 0.3121 (0.3448)\tIter time (s)  0.920 ( 0.920)\tEpoch time (h)  0.026 ( 0.026)\tRemain time (h)  0.024 ( 0.024)\tSeq Len 829.000 (829.000)\tCtx Len 147.000 (147.000)\tVis Len 682.000 (682.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 1.6666666666666667e-06\n",
      "Epoch: [0][  6/100]\tBatch time (s)  0.758 ( 0.758)\tLoss 0.4290 (0.4520)\tIter time (s)  0.379 ( 0.379)\tEpoch time (h)  0.011 ( 0.011)\tRemain time (h)  0.010 ( 0.010)\tSeq Len 392.000 (392.000)\tCtx Len 122.000 (122.000)\tVis Len 270.000 (270.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 2.0000000000000003e-06\n",
      "Epoch: [0][  7/100]\tBatch time (s)  0.951 ( 0.951)\tLoss 0.4161 (0.2993)\tIter time (s)  0.476 ( 0.476)\tEpoch time (h)  0.013 ( 0.013)\tRemain time (h)  0.012 ( 0.012)\tSeq Len 425.000 (425.000)\tCtx Len 145.000 (145.000)\tVis Len 280.000 (280.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 2.3333333333333336e-06\n",
      "Epoch: [0][  8/100]\tBatch time (s)  1.012 ( 1.012)\tLoss 0.3551 (0.4237)\tIter time (s)  0.506 ( 0.506)\tEpoch time (h)  0.014 ( 0.014)\tRemain time (h)  0.013 ( 0.013)\tSeq Len 511.000 (511.000)\tCtx Len 143.000 (143.000)\tVis Len 368.000 (368.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 2.666666666666667e-06\n",
      "Epoch: [0][  9/100]\tBatch time (s)  0.715 ( 0.715)\tLoss 0.4931 (0.4692)\tIter time (s)  0.357 ( 0.357)\tEpoch time (h)  0.010 ( 0.010)\tRemain time (h)  0.009 ( 0.009)\tSeq Len 346.000 (346.000)\tCtx Len 76.000 (76.000)\tVis Len 270.000 (270.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 3e-06\n",
      "Epoch: [0][ 10/100]\tBatch time (s)  1.215 ( 1.215)\tLoss 0.2326 (0.3081)\tIter time (s)  0.607 ( 0.607)\tEpoch time (h)  0.017 ( 0.017)\tRemain time (h)  0.015 ( 0.015)\tSeq Len 515.000 (515.000)\tCtx Len 147.000 (147.000)\tVis Len 368.000 (368.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 3.3333333333333333e-06\n",
      "Epoch: [0][ 11/100]\tBatch time (s)  1.400 ( 1.400)\tLoss 0.2133 (0.3347)\tIter time (s)  0.700 ( 0.700)\tEpoch time (h)  0.019 ( 0.019)\tRemain time (h)  0.017 ( 0.017)\tSeq Len 817.000 (817.000)\tCtx Len 145.000 (145.000)\tVis Len 672.000 (672.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 3.6666666666666666e-06\n",
      "Epoch: [0][ 12/100]\tBatch time (s)  0.999 ( 0.999)\tLoss 0.4306 (0.4047)\tIter time (s)  0.499 ( 0.499)\tEpoch time (h)  0.014 ( 0.014)\tRemain time (h)  0.012 ( 0.012)\tSeq Len 346.000 (346.000)\tCtx Len 76.000 (76.000)\tVis Len 270.000 (270.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 4.000000000000001e-06\n",
      "Epoch: [0][ 13/100]\tBatch time (s)  0.842 ( 0.842)\tLoss 0.3984 (0.4514)\tIter time (s)  0.421 ( 0.421)\tEpoch time (h)  0.012 ( 0.012)\tRemain time (h)  0.010 ( 0.010)\tSeq Len 515.000 (515.000)\tCtx Len 147.000 (147.000)\tVis Len 368.000 (368.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 4.333333333333334e-06\n",
      "Epoch: [0][ 14/100]\tBatch time (s)  1.580 ( 1.580)\tLoss 0.2695 (0.4491)\tIter time (s)  0.790 ( 0.790)\tEpoch time (h)  0.022 ( 0.022)\tRemain time (h)  0.019 ( 0.019)\tSeq Len 867.000 (867.000)\tCtx Len 147.000 (147.000)\tVis Len 720.000 (720.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 4.666666666666667e-06\n",
      "Epoch: [0][ 15/100]\tBatch time (s)  1.358 ( 1.358)\tLoss 0.4078 (0.3257)\tIter time (s)  0.679 ( 0.679)\tEpoch time (h)  0.019 ( 0.019)\tRemain time (h)  0.016 ( 0.016)\tSeq Len 514.000 (514.000)\tCtx Len 146.000 (146.000)\tVis Len 368.000 (368.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 5e-06\n",
      "Epoch: [0][ 16/100]\tBatch time (s)  0.971 ( 0.971)\tLoss 0.5224 (0.4137)\tIter time (s)  0.486 ( 0.486)\tEpoch time (h)  0.013 ( 0.013)\tRemain time (h)  0.011 ( 0.011)\tSeq Len 416.000 (416.000)\tCtx Len 141.000 (141.000)\tVis Len 275.000 (275.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 5.333333333333334e-06\n",
      "Epoch: [0][ 17/100]\tBatch time (s)  1.262 ( 1.262)\tLoss 0.2610 (0.3243)\tIter time (s)  0.631 ( 0.631)\tEpoch time (h)  0.018 ( 0.018)\tRemain time (h)  0.015 ( 0.015)\tSeq Len 767.000 (767.000)\tCtx Len 146.000 (146.000)\tVis Len 621.000 (621.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 5.666666666666667e-06\n",
      "Epoch: [0][ 18/100]\tBatch time (s)  0.752 ( 0.752)\tLoss 0.3976 (0.3862)\tIter time (s)  0.376 ( 0.376)\tEpoch time (h)  0.010 ( 0.010)\tRemain time (h)  0.009 ( 0.009)\tSeq Len 424.000 (424.000)\tCtx Len 148.000 (148.000)\tVis Len 276.000 (276.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 6e-06\n",
      "Epoch: [0][ 19/100]\tBatch time (s)  1.258 ( 1.258)\tLoss 0.4031 (0.3754)\tIter time (s)  0.629 ( 0.629)\tEpoch time (h)  0.017 ( 0.017)\tRemain time (h)  0.014 ( 0.014)\tSeq Len 522.000 (522.000)\tCtx Len 147.000 (147.000)\tVis Len 375.000 (375.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 6.333333333333333e-06\n",
      "Epoch: [0][ 20/100]\tBatch time (s)  1.172 ( 1.172)\tLoss 0.1934 (0.2874)\tIter time (s)  0.586 ( 0.586)\tEpoch time (h)  0.016 ( 0.016)\tRemain time (h)  0.013 ( 0.013)\tSeq Len 369.000 (369.000)\tCtx Len 97.000 (97.000)\tVis Len 272.000 (272.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 6.666666666666667e-06\n",
      "Epoch: [0][ 21/100]\tBatch time (s)  1.290 ( 1.290)\tLoss 0.2861 (0.2160)\tIter time (s)  0.645 ( 0.645)\tEpoch time (h)  0.018 ( 0.018)\tRemain time (h)  0.014 ( 0.014)\tSeq Len 683.000 (683.000)\tCtx Len 143.000 (143.000)\tVis Len 540.000 (540.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 7e-06\n",
      "Epoch: [0][ 22/100]\tBatch time (s)  0.920 ( 0.920)\tLoss 0.3792 (0.4042)\tIter time (s)  0.460 ( 0.460)\tEpoch time (h)  0.013 ( 0.013)\tRemain time (h)  0.010 ( 0.010)\tSeq Len 457.000 (457.000)\tCtx Len 145.000 (145.000)\tVis Len 312.000 (312.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 7.333333333333333e-06\n",
      "Epoch: [0][ 23/100]\tBatch time (s)  1.024 ( 1.024)\tLoss 0.1436 (0.1939)\tIter time (s)  0.512 ( 0.512)\tEpoch time (h)  0.014 ( 0.014)\tRemain time (h)  0.011 ( 0.011)\tSeq Len 515.000 (515.000)\tCtx Len 147.000 (147.000)\tVis Len 368.000 (368.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 7.666666666666667e-06\n",
      "Epoch: [0][ 24/100]\tBatch time (s)  1.048 ( 1.048)\tLoss 0.2720 (0.2723)\tIter time (s)  0.524 ( 0.524)\tEpoch time (h)  0.015 ( 0.015)\tRemain time (h)  0.011 ( 0.011)\tSeq Len 506.000 (506.000)\tCtx Len 122.000 (122.000)\tVis Len 384.000 (384.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 8.000000000000001e-06\n",
      "Epoch: [0][ 25/100]\tBatch time (s)  1.778 ( 1.778)\tLoss 0.2982 (0.3039)\tIter time (s)  0.889 ( 0.889)\tEpoch time (h)  0.025 ( 0.025)\tRemain time (h)  0.019 ( 0.019)\tSeq Len 673.000 (673.000)\tCtx Len 145.000 (145.000)\tVis Len 528.000 (528.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 8.333333333333334e-06\n",
      "Epoch: [0][ 26/100]\tBatch time (s)  1.156 ( 1.156)\tLoss 0.2696 (0.2165)\tIter time (s)  0.578 ( 0.578)\tEpoch time (h)  0.016 ( 0.016)\tRemain time (h)  0.012 ( 0.012)\tSeq Len 369.000 (369.000)\tCtx Len 99.000 (99.000)\tVis Len 270.000 (270.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 8.666666666666668e-06\n",
      "Epoch: [0][ 27/100]\tBatch time (s)  1.048 ( 1.048)\tLoss 0.3517 (0.2960)\tIter time (s)  0.524 ( 0.524)\tEpoch time (h)  0.015 ( 0.015)\tRemain time (h)  0.011 ( 0.011)\tSeq Len 510.000 (510.000)\tCtx Len 142.000 (142.000)\tVis Len 368.000 (368.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 9e-06\n",
      "Epoch: [0][ 28/100]\tBatch time (s)  0.927 ( 0.927)\tLoss 0.1725 (0.2251)\tIter time (s)  0.463 ( 0.463)\tEpoch time (h)  0.013 ( 0.013)\tRemain time (h)  0.009 ( 0.009)\tSeq Len 546.000 (546.000)\tCtx Len 143.000 (143.000)\tVis Len 403.000 (403.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 9.333333333333334e-06\n",
      "Epoch: [0][ 29/100]\tBatch time (s)  0.719 ( 0.719)\tLoss 0.3371 (0.3176)\tIter time (s)  0.360 ( 0.360)\tEpoch time (h)  0.010 ( 0.010)\tRemain time (h)  0.007 ( 0.007)\tSeq Len 342.000 (342.000)\tCtx Len 76.000 (76.000)\tVis Len 266.000 (266.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 9.666666666666667e-06\n",
      "Epoch: [0][ 30/100]\tBatch time (s)  1.469 ( 1.469)\tLoss 0.1920 (0.2110)\tIter time (s)  0.735 ( 0.735)\tEpoch time (h)  0.020 ( 0.020)\tRemain time (h)  0.014 ( 0.014)\tSeq Len 685.000 (685.000)\tCtx Len 145.000 (145.000)\tVis Len 540.000 (540.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 1e-05\n",
      "Epoch: [0][ 31/100]\tBatch time (s)  0.774 ( 0.774)\tLoss 0.3021 (0.2677)\tIter time (s)  0.387 ( 0.387)\tEpoch time (h)  0.011 ( 0.011)\tRemain time (h)  0.007 ( 0.007)\tSeq Len 416.000 (416.000)\tCtx Len 143.000 (143.000)\tVis Len 273.000 (273.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 9.989690721649485e-06\n",
      "Epoch: [0][ 32/100]\tBatch time (s)  0.960 ( 0.960)\tLoss 0.3887 (0.2860)\tIter time (s)  0.480 ( 0.480)\tEpoch time (h)  0.013 ( 0.013)\tRemain time (h)  0.009 ( 0.009)\tSeq Len 575.000 (575.000)\tCtx Len 146.000 (146.000)\tVis Len 429.000 (429.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 9.97938144329897e-06\n",
      "Epoch: [0][ 33/100]\tBatch time (s)  0.843 ( 0.843)\tLoss 0.2780 (0.2959)\tIter time (s)  0.421 ( 0.421)\tEpoch time (h)  0.012 ( 0.012)\tRemain time (h)  0.008 ( 0.008)\tSeq Len 515.000 (515.000)\tCtx Len 147.000 (147.000)\tVis Len 368.000 (368.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 9.969072164948454e-06\n",
      "Epoch: [0][ 34/100]\tBatch time (s)  0.807 ( 0.807)\tLoss 0.3059 (0.2264)\tIter time (s)  0.403 ( 0.403)\tEpoch time (h)  0.011 ( 0.011)\tRemain time (h)  0.007 ( 0.007)\tSeq Len 388.000 (388.000)\tCtx Len 122.000 (122.000)\tVis Len 266.000 (266.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 9.958762886597939e-06\n",
      "Epoch: [0][ 35/100]\tBatch time (s)  1.170 ( 1.170)\tLoss 0.2659 (0.2324)\tIter time (s)  0.585 ( 0.585)\tEpoch time (h)  0.016 ( 0.016)\tRemain time (h)  0.011 ( 0.011)\tSeq Len 512.000 (512.000)\tCtx Len 144.000 (144.000)\tVis Len 368.000 (368.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 9.948453608247423e-06\n",
      "Epoch: [0][ 36/100]\tBatch time (s)  0.933 ( 0.933)\tLoss 0.3540 (0.2753)\tIter time (s)  0.467 ( 0.467)\tEpoch time (h)  0.013 ( 0.013)\tRemain time (h)  0.008 ( 0.008)\tSeq Len 364.000 (364.000)\tCtx Len 76.000 (76.000)\tVis Len 288.000 (288.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 9.938144329896908e-06\n",
      "Epoch: [0][ 37/100]\tBatch time (s)  0.730 ( 0.730)\tLoss 0.3552 (0.3900)\tIter time (s)  0.365 ( 0.365)\tEpoch time (h)  0.010 ( 0.010)\tRemain time (h)  0.006 ( 0.006)\tSeq Len 384.000 (384.000)\tCtx Len 99.000 (99.000)\tVis Len 285.000 (285.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 9.927835051546392e-06\n",
      "Epoch: [0][ 38/100]\tBatch time (s)  1.388 ( 1.388)\tLoss 0.2233 (0.2195)\tIter time (s)  0.694 ( 0.694)\tEpoch time (h)  0.019 ( 0.019)\tRemain time (h)  0.012 ( 0.012)\tSeq Len 645.000 (645.000)\tCtx Len 145.000 (145.000)\tVis Len 500.000 (500.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 9.917525773195877e-06\n",
      "Epoch: [0][ 39/100]\tBatch time (s)  0.810 ( 0.810)\tLoss 0.3088 (0.3066)\tIter time (s)  0.405 ( 0.405)\tEpoch time (h)  0.011 ( 0.011)\tRemain time (h)  0.007 ( 0.007)\tSeq Len 513.000 (513.000)\tCtx Len 145.000 (145.000)\tVis Len 368.000 (368.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 9.907216494845361e-06\n",
      "Epoch: [0][ 40/100]\tBatch time (s)  1.261 ( 1.261)\tLoss 0.3367 (0.2477)\tIter time (s)  0.630 ( 0.630)\tEpoch time (h)  0.018 ( 0.018)\tRemain time (h)  0.011 ( 0.011)\tSeq Len 430.000 (430.000)\tCtx Len 100.000 (100.000)\tVis Len 330.000 (330.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 9.896907216494846e-06\n",
      "Epoch: [0][ 41/100]\tBatch time (s)  1.036 ( 1.036)\tLoss 0.2537 (0.2705)\tIter time (s)  0.518 ( 0.518)\tEpoch time (h)  0.014 ( 0.014)\tRemain time (h)  0.008 ( 0.008)\tSeq Len 537.000 (537.000)\tCtx Len 146.000 (146.000)\tVis Len 391.000 (391.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr: 9.88659793814433e-06\n",
      "Epoch: [0][ 42/100]\tBatch time (s)  0.820 ( 0.820)\tLoss 0.3351 (0.3186)\tIter time (s)  0.410 ( 0.410)\tEpoch time (h)  0.011 ( 0.011)\tRemain time (h)  0.007 ( 0.007)\tSeq Len 431.000 (431.000)\tCtx Len 146.000 (146.000)\tVis Len 285.000 (285.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 训练ShowUI模型\n",
    "ShowUItrain(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47da84a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并LoRA权重和原始模型\n",
    "ShowUImerge(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4918e3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ShowUI模型推理\n",
    "\n",
    "class ShowUI:\n",
    "    def __init__(self, model_path: str, args):\n",
    "        self.model_path = model_path\n",
    "        self.model = None\n",
    "        self.processor = None\n",
    "        self.args = args\n",
    "\n",
    "    def load_model(self):\n",
    "\n",
    "        torch_dtype = torch.float32\n",
    "        if self.args.precision == \"bf16\":\n",
    "            torch_dtype = torch.bfloat16\n",
    "        elif self.args.precision == \"fp16\":\n",
    "            torch_dtype = torch.half\n",
    "        \n",
    "        print(\"Loading processor...\")\n",
    "        \n",
    "        from model.showui.processing_showui import ShowUIProcessor\n",
    "\n",
    "        self.processor = ShowUIProcessor.from_pretrained(self.args.model_path,\n",
    "                                                min_pixels=self.args.min_visual_tokens *28*28,\n",
    "                                                max_pixels=self.args.max_visual_tokens *28*28,\n",
    "                                                model_max_length=self.args.model_max_length,\n",
    "                                                uigraph_train=self.args.uigraph_train, uigraph_test=self.args.uigraph_test,\n",
    "                                                uigraph_diff=self.args.uigraph_diff,  uigraph_rand=self.args.uigraph_rand,\n",
    "                                                uimask_pre=self.args.uimask_pre, uimask_ratio=self.args.uimask_ratio, uimask_rand=self.args.uimask_rand,\n",
    "                                                size = {\"shortest_edge\": 3136, \"longest_edge\": 1003520}\n",
    "                                              )\n",
    "        \n",
    "        print(\"Processor loaded successfully.\")\n",
    "\n",
    "        print(f\"Loading model from {self.model_path}...\")\n",
    "\n",
    "        bnb_config = BitsAndBytesConfig(\n",
    "                    load_in_4bit=True,\n",
    "                    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                    bnb_4bit_use_double_quant=True,\n",
    "                    bnb_4bit_quant_type=\"nf4\",\n",
    "                    llm_int8_skip_modules=[\"img_projection\"],\n",
    "                ) if self.args.use_qlora else None\n",
    "\n",
    "        from model.utils import parse_layer_type\n",
    "        from model.showui.modeling_showui import ShowUIForConditionalGeneration\n",
    "\n",
    "        lm_qwen_layer = 28\n",
    "        vis_qwen_layer = 32\n",
    "        lm_skip_layer = parse_layer_type(self.args.lm_skip_layer, lm_qwen_layer)\n",
    "        vis_skip_layer = parse_layer_type(self.args.vis_skip_layer, vis_qwen_layer)\n",
    "\n",
    "        self.model = ShowUIForConditionalGeneration.from_pretrained(\n",
    "                                                    self.args.model_path,\n",
    "                                                    torch_dtype=torch_dtype, # 模型精度\n",
    "                                                    low_cpu_mem_usage=True, # 低内存使用模式\n",
    "                                                    _attn_implementation=self.args.attn_imple, # 注意力实现方式\n",
    "                                                    # quantization_config=bnb_config, # 量化配置\n",
    "                                                    device_map=\"cuda\", # 自动设备映射\n",
    "                                                    lm_skip_layer=lm_skip_layer, # 跳过语言层\n",
    "                                                    lm_skip_ratio=self.args.lm_skip_ratio, # 跳过语言层比例\n",
    "    )\n",
    "        \n",
    "        print(\"Model loaded successfully.\")\n",
    "\n",
    "    def invoke(self, img_url: str, query: str, args):\n",
    "        image = Image.open(img_url)\n",
    "\n",
    "        print(f\"Image loaded from {img_url}, size: {image.size}\")\n",
    "        print(f\"Query: {query}\")\n",
    "        \n",
    "\n",
    "        print(\"Processing messages for model input...\")\n",
    "\n",
    "        _SYSTEM = (\n",
    "            \"Based on the screenshot of the page, I give a text description and you give its corresponding location. \"\n",
    "            \"The coordinate represents a clickable location [x, y] for an element, which is a relative coordinate on the screenshot, scaled from 0 to 1.\"\n",
    "        )\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": _SYSTEM},\n",
    "                    {\"type\": \"image\", \"image\": img_url, \"min_pixels\": self.args.min_visual_tokens * 28 * 28, \"max_pixels\": self.args.max_visual_tokens * 28 * 28},\n",
    "                    {\"type\": \"text\", \"text\": query}\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        text = self.processor.apply_chat_template(\n",
    "            messages, tokenize=False, add_generation_prompt=True,\n",
    "        )\n",
    "        image_inputs, video_inputs = process_vision_info(messages)\n",
    "        inputs = self.processor(\n",
    "            text=[text],\n",
    "            images=image_inputs,\n",
    "            videos=video_inputs,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        inputs = inputs.to(\"cuda\")\n",
    "        print(\"Inputs prepared for model generation.\")\n",
    "        generated_ids = self.model.generate(**inputs, max_new_tokens=128)\n",
    "        generated_ids_trimmed = [\n",
    "            out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "        print(\"Model generation completed.\")\n",
    "        print(\"Decoding generated IDs to text...\")\n",
    "        output_text = self.processor.batch_decode(\n",
    "            generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "        )[0]\n",
    "        print(f\"Output text: {output_text}\")\n",
    "        print(\"Decoding completed.\")\n",
    "        \n",
    "        click_xy = ast.literal_eval(output_text)\n",
    "        x, y = click_xy[0] * image.width, click_xy[1] * image.height\n",
    "\n",
    "        \n",
    "        return x, y, image\n",
    "\n",
    "    def draw_point(self, image, x, y, radius=2):\n",
    "        print(f\"Drawing point at ({x}, {y}) with radius {radius} on the image.\")\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        draw.ellipse((x - radius, y - radius, x + radius, y + radius), fill='red', outline='red')\n",
    "        image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dbd28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 ShowUI 实例并加载模型\n",
    "model_path = args.exp_dir + \"/ckpt_model/merged_model\"\n",
    "showui = ShowUI(model_path,args)\n",
    "showui.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bc3700",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_url = \"D:/Project/my_dataset/unlabel_images/image0.png\"\n",
    "query = \"请输入密码\"\n",
    "\n",
    "x, y, image = showui.invoke(img_url, query, args)\n",
    "print(f\"Click coordinates: ({x}, {y})\")\n",
    "showui.draw_point(image, x, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
