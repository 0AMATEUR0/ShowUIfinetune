{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "574c45b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "import wandb\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from PIL import Image, ImageDraw\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from transformers import BitsAndBytesConfig, AutoProcessor, get_linear_schedule_with_warmup\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from model.utils import find_target_linear_names\n",
    "from main.trainer import train\n",
    "from main.eval_aitw import validate_aitw\n",
    "from main.eval_mind2web import validate_mind2web\n",
    "from main.eval_screenspot import validate_screenspot\n",
    "from main.evaluator import validate as validate_default\n",
    "from data.dataset import HybridDataset, collate_fn\n",
    "from utils.utils import save_args_to_json, create_log_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f11f347",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    # wandb配置参数\n",
    "    \"wandb_key\": \"7dd9f7e0d1d48f0b0296d469ce4b6365e615094d\", # 修改为你的wandb API key\n",
    "\n",
    "    # 需要修改的路径参数\n",
    "    \"model_path\": \"D:/Project/showui-2b\", # 修改为你的基模型路径\n",
    "    \"train_dataset\": \"screenspot\", # 修改为你的训练数据集路径\n",
    "    \"train_json\": \"metadata\", # 修改为你的训练数据集标注文件名\n",
    "    \"val_dataset\": \"screenspot\", # 修改为你的验证数据集路径\n",
    "    \"val_json\": \"metadata\", # 修改为你的验证数据集标注文件名\n",
    "    \"dataset_dir\": \"D:/Project/my_dataset\", # 修改为你的数据集目录路径\n",
    "    \"exp_dir\": \"D:/Project/MODELS\", # 请修改为你的LoRA权重保存路径\n",
    "\n",
    "    # 模型配置参数\n",
    "    \"model_id\": \"local_ShowUI-2B\", # 模型ID\n",
    "    \"version\": \"showlab/ShowUI-2B\", # 模型版本路径\n",
    "    \"min_visual_tokens\": 256, # 最小视觉token数量\n",
    "    \"max_visual_tokens\": 1280, # 最大视觉token数量\n",
    "    \"model_max_length\": 8192, # 模型最大长度，8192表示支持长文本输入\n",
    "\n",
    "    # ui图配置参数\n",
    "    \"uigraph_train\": True, # 启用ui图训练\n",
    "    \"uigraph_test\": False, # 启用ui图测试\n",
    "    \"uigraph_diff\": 1, # UI图差异阈值，1表示仅保留有差异的patch\n",
    "    \"uigraph_rand\": False, # 是否随机选择patch进行训练，False表示均匀选择\n",
    "    \"uimask_pre\": True, # 是否预处理UI图，True表示预处理\n",
    "    \"uimask_ratio\": 0.5, # UI图掩码比例，0.5表示50%的UI图被掩码\n",
    "    \"uimask_rand\": False, # 是否随机掩码UI图，False表示均匀掩码\n",
    "    \n",
    "    \"precision\": \"bf16\", # 训练精度，支持\"fp16\", \"bf16\", \"fp32\"\n",
    "    \n",
    "    # 语言和视觉层跳过参数\n",
    "    \"lm_skip_ratio\": 0.5, # 语言层跳过比例，0.5表示跳过50%的语言层\n",
    "    \"lm_skip_layer\": '[1,28,0]', # 语言层跳过层数，e.g., [1,28,0]表示跳过第1层和第28层\n",
    "    \"vis_skip_layer\": '[1,32,0]', # 视觉层跳过层数，e.g., [1,32,0]表示跳过第1层和第32层\n",
    "    \"attn_imple\": \"sdpa\", # 注意力实现方式，支持\"flash_attention_2\", \"sdpa\", \"eager\"\n",
    "    \n",
    "    # LoRA微调配置参数\n",
    "    \"use_qlora\": False, # 是否使用QLoRA进行训练\n",
    "    \"lora_r\": 8, # LoRA的r值，表示低秩矩阵的秩\n",
    "    \"lora_alpha\": 16, # LoRA的alpha值，表示缩放因子\n",
    "    \"lora_dropout\": 0.05, # LoRA的dropout率\n",
    "    \"lora_target_modules\": [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"], # LoRA目标模块，支持\"qkv_proj\", \"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"\n",
    "    \"tune_visual_encoder\": False, # 是否微调视觉编码器\n",
    "    \"freeze_lm_embed\": False, # 是否冻结语言模型嵌入层\n",
    "\n",
    "    # 梯度检查点配置参数\n",
    "    \"gradient_checkpointing\": True, # 是否启用梯度检查点\n",
    "    \"tune_visual_encoder_projector\": False, # 是否微调视觉编码器投影层\n",
    "\n",
    "    # 数据集配置参数\n",
    "    \"train_ratio\": \"1.0\", # 训练数据比例，可以是0到1之间的浮点数\n",
    "    \"val_ratio\": \"1.0\", # 验证数据比例，可以是0到1之间的浮点数\n",
    "    \"uniform_sample\": False, # 是否使用均匀采样进行训练数据采样\n",
    "    \"random_sample\": False, # 是否使用随机采样进行训练数据采样\n",
    "    \"record_sample\": False, # 是否记录采样数据\n",
    "\n",
    "    # 训练配置参数\n",
    "    \"log_base_dir\": \"D:/Project/logs\", # 日志基础目录\n",
    "    \"exp_id\": \"debug\", # 实验ID，用于区分不同实验\n",
    "    \"lr\": 3e-4, # 学习率\n",
    "    \"beta1\": 0.9, # 优化器的Beta1参数\n",
    "    \"beta2\": 0.999, # 优化器的Beta2参数\n",
    "    \"epochs\": 1, # 训练轮数\n",
    "    \"steps_per_epoch\": 5, # 每个epoch的训练步数\n",
    "    \"warmup_steps\": 0, # 预热步数\n",
    "    \"batch_size\": 2, # 训练批次大小\n",
    "    \"grad_accumulation_steps\": 8, # 梯度累积步数\n",
    "    \"val_batch_size\": 1, # 验证批次大小\n",
    "    \"workers\": 4, # 数据加载器工作线程数\n",
    "\n",
    "    # Grounding setting\n",
    "    \"num_turn\": 100, # 交互轮数\n",
    "    \"shuffle_image_token\": True, # 随机打乱图像token顺序\n",
    "    \"uniform_prompt\": True, # 使用统一的提示词\n",
    "    \"text2point\": 1.0, # 文本到点的任务采样比例\n",
    "    \"text2bbox\": 0.0, # 文本到边界框的任务采样比例\n",
    "    \"point2text\": 0.0, # 点到文本的任务采样比例\n",
    "    \"bbox2text\": 0.0, # 边界框到文本的任务采样比例\n",
    "    \"crop_min\": 1.0 , # 裁剪最小比例，1.0表示不裁剪\n",
    "    \"crop_max\": 1.0, # 裁剪最大比例，1.0表示不裁剪\n",
    "    \"xy_int\": False, # 是否将坐标转换为整数\n",
    "\n",
    "    # Navigation setting\n",
    "    \"num_history\": 4, # 历史交互轮数\n",
    "    \"interleaved_history\": 'tttt', # 视觉-动作交互设置，选项=['tttt', 'vvvv', 'vtvt', 'tvtv', 'vvtt', 'ttvv']\n",
    "    \"skip_readme_train\": False, # 是否跳过README训练数据\n",
    "    \"skip_readme_test\": False, # 是否跳过README测试数据\n",
    "\n",
    "    # 模型检测点和评估配置参数\n",
    "    \"eval_only\": False, # 是否仅进行评估，不进行训练\n",
    "    \"start_epoch\": 0, # 开始训练的epoch\n",
    "    \"no_eval\": False, # 是否跳过评估\n",
    "    \"debug\": False, # debug模式，True表示启用，不保存模型日志\n",
    "    \"print_freq\": 1, # 输出频率，表示每隔多少步输出一次日志\n",
    "\n",
    "\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f351fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "# 如果args是字典，将其转换为SimpleNamespace对象\n",
    "if isinstance(args, dict):\n",
    "    args = SimpleNamespace(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18458e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型主函数\n",
    "def ShowUItrain(args):\n",
    "\n",
    "    args.global_rank = int(os.environ.get(\"RANK\", 0))\n",
    "    args.local_rank = int(os.environ.get(\"LOCAL_RANK\", 0))\n",
    "    args.world_size = int(os.environ.get(\"WORLD_SIZE\", 1))\n",
    "\n",
    "\n",
    "    if args.attn_imple in [\"eager\", \"sdpa\"]:\n",
    "        # suggested by https://github.com/Lightning-AI/litgpt/issues/327\n",
    "        torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "        torch.backends.cuda.enable_flash_sdp(False)\n",
    "\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "    args.distributed = args.world_size > 1\n",
    "\n",
    "\n",
    "    args.log_dir = os.path.join(args.log_base_dir, args.exp_id, timestamp)\n",
    "    args.tmp_dir = os.path.join(args.log_dir, \"tmp\")\n",
    "\n",
    "    # must provide wandb-key\n",
    "    assert args.wandb_key is not None\n",
    "    wandb.login(key=args.wandb_key)\n",
    "\n",
    "\n",
    "    writer = None  # TensorBoard writer, if needed, can be initialized later\n",
    "    os.makedirs(args.log_dir, exist_ok=True)\n",
    "    os.makedirs(args.tmp_dir, exist_ok=True)\n",
    "    save_args_to_json(args, os.path.join(args.log_dir, \"args.json\"))  # 保存参数\n",
    "    if not args.debug:\n",
    "        # 创建TensorBoard日志目录\n",
    "        writer = SummaryWriter(os.path.join(args.log_dir, \"tensorboard\"))\n",
    "        # 初始化wandb\n",
    "        wandb.init(\n",
    "            project=\"ShowUI\",\n",
    "            group=args.exp_id,\n",
    "            name=f'{args.exp_id}_{timestamp}',\n",
    "            config=args,\n",
    "            dir=args.log_dir,\n",
    "        )\n",
    "    print(f\"Start Job: {args.exp_id}\")\n",
    "\n",
    "    # 创建处理器\n",
    "\n",
    "    from model.showui.processing_showui import ShowUIProcessor\n",
    "\n",
    "    processor = ShowUIProcessor.from_pretrained(args.model_path,\n",
    "                                                min_pixels=args.min_visual_tokens *28*28,\n",
    "                                                max_pixels=args.max_visual_tokens *28*28,\n",
    "                                                model_max_length=args.model_max_length,\n",
    "                                                uigraph_train=args.uigraph_train, uigraph_test=args.uigraph_test,\n",
    "                                                uigraph_diff=args.uigraph_diff,  uigraph_rand=args.uigraph_rand,\n",
    "                                                uimask_pre=args.uimask_pre, uimask_ratio=args.uimask_ratio, uimask_rand=args.uimask_rand,\n",
    "                                                size = {\"shortest_edge\": 3136, \"longest_edge\": 1003520}\n",
    "                                              )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # 创建模型\n",
    "    torch_dtype = torch.float32\n",
    "    if args.precision == \"bf16\":\n",
    "        torch_dtype = torch.bfloat16\n",
    "    elif args.precision == \"fp16\":\n",
    "        torch_dtype = torch.half\n",
    "\n",
    "    model_path = args.model_path\n",
    "    \n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "                    load_in_4bit=True,\n",
    "                    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                    bnb_4bit_use_double_quant=True,\n",
    "                    bnb_4bit_quant_type=\"nf4\",\n",
    "                    llm_int8_skip_modules=[\"img_projection\"],\n",
    "                ) if args.use_qlora else None # 仅在使用QLoRA时才需要配置\n",
    "    \n",
    "    from model.utils import parse_layer_type\n",
    "    from model.showui.modeling_showui import ShowUIForConditionalGeneration\n",
    "\n",
    "    lm_qwen_layer = 28\n",
    "    vis_qwen_layer = 32\n",
    "    lm_skip_layer = parse_layer_type(args.lm_skip_layer, lm_qwen_layer)\n",
    "    vis_skip_layer = parse_layer_type(args.vis_skip_layer, vis_qwen_layer)\n",
    "\n",
    "    model = ShowUIForConditionalGeneration.from_pretrained(\n",
    "        model_path,\n",
    "        torch_dtype=torch_dtype, # 模型精度\n",
    "        low_cpu_mem_usage=True, # 低内存使用模式\n",
    "        _attn_implementation=args.attn_imple, # 注意力实现方式\n",
    "        # quantization_config=bnb_config, # 量化配置\n",
    "        device_map=\"cuda\", # 自动设备映射\n",
    "        lm_skip_layer=lm_skip_layer, # 跳过语言层\n",
    "        lm_skip_ratio=args.lm_skip_ratio, # 跳过语言层比例\n",
    "        tie_word_embeddings=False, # 是否共享词嵌入\n",
    "    )\n",
    "\n",
    "    # 保存 untied 模型\n",
    "    model.save_pretrained(\"D:/Project/MODELS\")\n",
    "    model.config.save_pretrained(\"D:/Project/MODELS\")\n",
    "\n",
    "\n",
    "    # 加载模型检测点\n",
    "    # if args.version != args.model_id:\n",
    "    #     state_dict = torch.load(args.version, map_location=\"cpu\")\n",
    "    #     model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    model.config.use_cache = False # 禁用缓存以节省内存\n",
    "\n",
    "    # 在评估模式下，不需要加载LoRA\n",
    "    if args.eval_only:\n",
    "        print(\"evaluation mode, thus set the `lora_r' as zero.\")\n",
    "        args.lora_r = 0\n",
    "    if not args.eval_only and args.use_qlora:\n",
    "        model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "    # 配置LoRA\n",
    "    lora_r = args.lora_r\n",
    "    if lora_r > 0:\n",
    "        lora_alpha = args.lora_alpha\n",
    "        lora_dropout = args.lora_dropout\n",
    "        exclude_module = [\"visual\"] if not args.tune_visual_encoder else []\n",
    "        exclude_module += [\"lm_head\"] if args.freeze_lm_embed else exclude_module\n",
    "        lora_target_modules = find_target_linear_names(model, lora_namespan_exclude=exclude_module)\n",
    "\n",
    "        lora_config = LoraConfig(\n",
    "            r=lora_r,\n",
    "            lora_alpha=lora_alpha,\n",
    "            target_modules=lora_target_modules,\n",
    "            lora_dropout=lora_dropout,\n",
    "            bias=\"none\",\n",
    "            task_type=\"CAUSAL_LM\",\n",
    "        )\n",
    "        model = get_peft_model(model, lora_config)\n",
    "        # model.print_trainable_parameters()\n",
    "\n",
    "        # 如果使用LoRA，则原始模型被包装2次\n",
    "        # 一次是peft的get_peft_model包装，一次是ShowUIForConditionalGeneration的包装\n",
    "        model_child = model.model.model # 获取原始模型，疑似不可使用base_model方法\n",
    "    else:\n",
    "        # 如果不使用LoRA，则原始模型只被ShowUIForConditionalGeneration包装\n",
    "        model_child = model.model\n",
    "    \n",
    "    # 梯度检查点，降低显存使用\n",
    "    if args.gradient_checkpointing:\n",
    "        model.gradient_checkpointing_enable()\n",
    "        model.enable_input_require_grads()\n",
    "    \n",
    "    if not args.tune_visual_encoder:\n",
    "        # 冻结视觉编码器\n",
    "        if args.lora_r > 0:\n",
    "            for p in model.base_model.model.visual.parameters():\n",
    "                p.requires_grad = False\n",
    "        elif args.lora_r == 0:\n",
    "            for p in model.visual.parameters():\n",
    "                p.requires_grad = False\n",
    "        \n",
    "    if args.tune_visual_encoder_projector:\n",
    "        for k, p in model.named_parameters():\n",
    "            if 'visual.merger' in k:\n",
    "                p.requires_grad = True\n",
    "    \n",
    "    if args.freeze_lm_embed:\n",
    "        if args.lora_r > 0:\n",
    "            for p in model_child.embed_tokens.parameters():\n",
    "                p.requires_grad = False\n",
    "        elif args.lora_r == 0:\n",
    "            for p in model_child.embed_tokens.parameters():\n",
    "                p.requires_grad = False\n",
    "    \n",
    "    # 检查可训练参数\n",
    "    list_of_params_to_optimize = []\n",
    "    for n, p in model.named_parameters():\n",
    "        if p.requires_grad:\n",
    "            # print(\"[Name]\", n, \" [Shape]\", p.shape)\n",
    "            list_of_params_to_optimize.append(p)\n",
    "    \n",
    "    # 创建数据集\n",
    "    args.samples_per_epoch = args.batch_size    \\\n",
    "                    * args.grad_accumulation_steps  \\\n",
    "                    * args.steps_per_epoch\n",
    "\n",
    "    train_dataset = HybridDataset(\n",
    "        processor,\n",
    "        inference=False,  # 仅用于训练\n",
    "        args=args,\n",
    "    )\n",
    "    \n",
    "    val_dataset = HybridDataset(\n",
    "        processor,\n",
    "        inference=True,  # 仅用于验证\n",
    "        args=args,\n",
    "    )\n",
    "\n",
    "    if args.val_dataset == \"mind2web\":\n",
    "        validate = validate_mind2web\n",
    "    elif args.val_dataset == \"screenspot\":\n",
    "        validate = validate_screenspot\n",
    "    elif args.val_dataset == \"aitw\":\n",
    "        validate = validate_aitw\n",
    "    else:\n",
    "        validate = validate_default\n",
    "\n",
    "    if not args.random_sample:\n",
    "        args.steps_per_epoch = len(train_dataset) // (args.batch_size * args.world_size)\n",
    "    print(\"step for epoch: \", args.steps_per_epoch)\n",
    "    # deepspeed参数（待完成）\n",
    "    # 如果使用DeepSpeed，参考https://github.com/showlab/ShowUI/blob/main/train.py\n",
    "\n",
    "    # LoRA微调\n",
    "    if lora_r > 0:\n",
    "        print(\"LoRA training, r: {}, alpha: {}, dropout: {}\".format(\n",
    "            lora_r, lora_alpha, lora_dropout))\n",
    "        # 创建优化器\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            list_of_params_to_optimize,\n",
    "            lr=args.lr,\n",
    "            betas=(args.beta1, args.beta2),\n",
    "            weight_decay=0.0,\n",
    "            )\n",
    "\n",
    "        \n",
    "\n",
    "        # DeepSpeed 用的是 WarmupDecayLR，PyTorch 没有内置这个，但可以用类似的调度器\n",
    "        total_steps = args.epochs * args.steps_per_epoch\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=args.warmup_steps,\n",
    "            num_training_steps=total_steps,\n",
    "        )\n",
    "\n",
    "        # 创建数据加载器\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=args.batch_size,\n",
    "            shuffle=True,\n",
    "            collate_fn=partial(collate_fn, processor=processor),\n",
    "            num_workers=args.workers,  # 根据你的CPU核心数调整\n",
    "        )\n",
    "        \n",
    "\n",
    "        # 模型引擎\n",
    "        model_engine = model\n",
    "        model_engine = model_engine.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "        \n",
    "\n",
    "    # 如果不使用LoRA微调\n",
    "    # 暂时一样，但是方便后续扩展\n",
    "    elif lora_r == 0 and not args.eval_only:\n",
    "        # 创建优化器\n",
    "        print(\"No LoRA, using full model training\")\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            list_of_params_to_optimize,\n",
    "            lr=args.lr,\n",
    "            betas=(args.beta1, args.beta2),\n",
    "            weight_decay=0.0,\n",
    "            )\n",
    "\n",
    "        # DeepSpeed 用的是 WarmupDecayLR，PyTorch 没有内置这个，但可以用类似的调度器\n",
    "        total_steps = args.epochs * args.steps_per_epoch\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=args.warmup_steps,\n",
    "            num_training_steps=total_steps,\n",
    "        )\n",
    "\n",
    "        # 创建数据加载器\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=args.batch_size,\n",
    "            shuffle=True,\n",
    "            collate_fn=partial(collate_fn, processor=processor),\n",
    "            num_workers=args.workers,  # 根据你的CPU核心数调整\n",
    "        )\n",
    "\n",
    "        # 模型引擎\n",
    "        model_engine = model\n",
    "        model_engine = model_engine.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "    # 仅评估模式\n",
    "    elif args.eval_only:\n",
    "        print(\"Evaluation mode, no training\")\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False \n",
    "        model_engine = model\n",
    "    else:\n",
    "        raise ValueError(\"Invalid setting\")\n",
    "    \n",
    "\n",
    "    # 断点加载（待完成）\n",
    "\n",
    "    # 验证集\n",
    "    if val_dataset is not None:\n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=args.val_batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=args.workers,\n",
    "            pin_memory=False,\n",
    "            sampler= None,  # 若分布式训练，此处参考https://github.com/showlab/ShowUI/blob/main/train.py\n",
    "            collate_fn=partial(collate_fn, processor=processor)\n",
    "        )\n",
    "    else:\n",
    "        val_loader = None\n",
    "    \n",
    "    if args.eval_only:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model_engine = model_engine.to(device)\n",
    "        validate(val_loader, model_engine, processor, 0, 0, writer, args)\n",
    "        exit()\n",
    "\n",
    "    train_iter = iter(train_loader)\n",
    "    best_score = 0.0\n",
    "    # args.start_epoch 是为了支持断点恢复训练\n",
    "    print(\"Start training\")\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        # train for one epoch\n",
    "        train_iter, global_step = train(\n",
    "            train_loader,\n",
    "            model_engine,\n",
    "            optimizer,\n",
    "            epoch,\n",
    "            scheduler,\n",
    "            writer,\n",
    "            train_iter,\n",
    "            args,\n",
    "        )\n",
    "\n",
    "        if args.no_eval == False and val_loader is not None:\n",
    "            score = validate(\n",
    "                val_loader,\n",
    "                model_engine,\n",
    "                processor,\n",
    "                epoch,\n",
    "                global_step,\n",
    "                writer,\n",
    "                args,\n",
    "            )\n",
    "            is_best = score > best_score\n",
    "            best_score = max(score, best_score)\n",
    "        else:\n",
    "            is_best = True\n",
    "            score = 0.0\n",
    "        \n",
    "        if args.no_eval or is_best:\n",
    "            save_dir = os.path.join(args.log_dir,\"ckpt_model\")\n",
    "            \n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            torch.save(\n",
    "                {\"epoch\": epoch},\n",
    "                os.path.join(\n",
    "                    save_dir,\n",
    "                    \"meta_log_epo{:.0f}_score{:.2f}.pth\".format(\n",
    "                            epoch, best_score\n",
    "                        ),\n",
    "                ),\n",
    "            )\n",
    "            # if args.distributed:\n",
    "            #     # 确保所有进程都完成保存\n",
    "            #     torch.distributed.barrier()\n",
    "            try:\n",
    "                torch.save(\n",
    "                    model_engine.state_dict(),\n",
    "                    os.path.join(\n",
    "                        save_dir,\n",
    "                        \"model_epo{:.0f}_score{:.2f}.pth\".format(\n",
    "                            epoch, best_score\n",
    "                        ),\n",
    "                    ),\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(\"Failed to save checkpoint (): \", e)\n",
    "    \n",
    "    \n",
    "    if args.global_rank == 0:\n",
    "        if not args.debug:\n",
    "            wandb.finish()\n",
    "            writer.close()\n",
    "\n",
    "# 合并LoRA权重和原始模型\n",
    "def ShowUImerge(args):\n",
    "    json_url = os.path.join(args.exp_dir, \"args.json\")\n",
    "    with open(json_url,'r') as f:\n",
    "        json_args = json.load(f)\n",
    "    for key, value in json_args.items():\n",
    "        setattr(args, key, value)\n",
    "    \n",
    "    args.save_path = args.exp_dir +\"/ckpt_model/merged_model\"\n",
    "    args.weight_url = args.exp_dir +\"/ckpt_model/adapter_model.safetensors\"\n",
    "\n",
    "    torch_dtype = torch.float32\n",
    "    if args.precision == \"bf16\":\n",
    "        torch_dtype = torch.bfloat16\n",
    "    elif args.precision == \"fp16\":\n",
    "        torch_dtype = torch.half\n",
    "    \n",
    "    from model.showui.processing_showui import ShowUIProcessor\n",
    "\n",
    "    model_url = args.model_path\n",
    "\n",
    "    processor = ShowUIProcessor.from_pretrained(args.model_path,\n",
    "                                                min_pixels=args.min_visual_tokens *28*28,\n",
    "                                                max_pixels=args.max_visual_tokens *28*28,\n",
    "                                                model_max_length=args.model_max_length,\n",
    "                                                uigraph_train=args.uigraph_train, uigraph_test=args.uigraph_test,\n",
    "                                                uigraph_diff=args.uigraph_diff,  uigraph_rand=args.uigraph_rand,\n",
    "                                                uimask_pre=args.uimask_pre, uimask_ratio=args.uimask_ratio, uimask_rand=args.uimask_rand,\n",
    "                                                size = {\"shortest_edge\": 3136, \"longest_edge\": 1003520}\n",
    "                                              )\n",
    "    \n",
    "    from model.utils import parse_layer_type\n",
    "    from model.showui.modeling_showui import ShowUIForConditionalGeneration\n",
    "\n",
    "    lm_qwen_layer = 28\n",
    "    vis_qwen_layer = 32\n",
    "    lm_skip_layer = parse_layer_type(args.lm_skip_layer, lm_qwen_layer)\n",
    "    vis_skip_layer = parse_layer_type(args.vis_skip_layer, vis_qwen_layer)\n",
    "\n",
    "    model = ShowUIForConditionalGeneration.from_pretrained(\n",
    "        args.model_path,\n",
    "        torch_dtype=torch_dtype, # 模型精度\n",
    "        low_cpu_mem_usage=True, # 低内存使用模式\n",
    "        _attn_implementation=args.attn_imple, # 注意力实现方式\n",
    "        # quantization_config=bnb_config, # 量化配置\n",
    "        device_map=\"cuda\", # 自动设备映射\n",
    "        lm_skip_layer=lm_skip_layer, # 跳过语言层\n",
    "        lm_skip_ratio=args.lm_skip_ratio, # 跳过语言层比例\n",
    "    )\n",
    "    \n",
    "    model.config.use_cache = False\n",
    "    model.config.tokenizer_model_max_length = processor.tokenizer.model_max_length\n",
    "\n",
    "    lora_r = args.lora_r\n",
    "    if lora_r > 0:\n",
    "        lora_alpha = args.lora_alpha\n",
    "        lora_dropout = args.lora_dropout\n",
    "        lora_target_modules = find_target_linear_names(model, lora_namespan_exclude=[\"visual\"])\n",
    "        lora_config = LoraConfig(\n",
    "            r=lora_r,\n",
    "            lora_alpha=lora_alpha,\n",
    "            target_modules=lora_target_modules,\n",
    "            lora_dropout=lora_dropout,\n",
    "            bias=\"none\",\n",
    "            task_type=\"CAUSAL_LM\",\n",
    "        )\n",
    "        model = get_peft_model(model, lora_config)\n",
    "        model.print_trainable_parameters()\n",
    "    \n",
    "\n",
    "        # 合并LoRA权重\n",
    "        print(\"Merging LoRA weights...\")\n",
    "        model = model.merge_and_unload()\n",
    "\n",
    "        # 将合并后的模型权重保存到指定路径\n",
    "        print(f\"Saving merged model to {args.save_path}\")\n",
    "        model.save_pretrained(\n",
    "            args.save_path,\n",
    "            max_shard_size=\"10GB\",  # 分片大小\n",
    "            safe_serialization=True,  # 安全序列化\n",
    "        )\n",
    "        processor.save_pretrained(args.save_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503774e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\AMATEUR\\_netrc\n",
      "wandb: Currently logged in as: aa1687159592 (aa1687159592-) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>D:/Project/logs\\debug\\2025-06-22_14-20-05\\wandb\\run-20250622_142007-2errkixt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aa1687159592-/ShowUI/runs/2errkixt' target=\"_blank\">debug_2025-06-22_14-20-05</a></strong> to <a href='https://wandb.ai/aa1687159592-/ShowUI' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aa1687159592-/ShowUI' target=\"_blank\">https://wandb.ai/aa1687159592-/ShowUI</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aa1687159592-/ShowUI/runs/2errkixt' target=\"_blank\">https://wandb.ai/aa1687159592-/ShowUI/runs/2errkixt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Job: debug\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:model.showui.modeling_showui:`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 197 lora modules: ['model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'lm_head']\n",
      "Dataset: Screenspot; Split: metadata; # samples: 476\n",
      "Loading 1 Training Datasets\n",
      "Dataset: Screenspot; Split: metadata; # samples: 476\n",
      "Loading 1 Validation Datasets\n",
      "step for epoch:  238\n",
      "LoRA training, r: 8, alpha: 16, dropout: 0.05\n",
      "Start training\n",
      "Current lr: 0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][  1/238]\tBatch time (s)  7.948 ( 7.948)\tIter time (s)  0.994 ( 0.994)\tEpoch time (h)  0.066 ( 0.066)\tRemain time (h)  0.065 ( 0.065)\tLoss 8.0954 (12.2431)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      "d:\\Anaconda\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][  2/238]\tBatch time (s)  8.015 ( 8.015)\tIter time (s)  1.002 ( 1.002)\tEpoch time (h)  0.066 ( 0.066)\tRemain time (h)  0.066 ( 0.066)\tLoss 5.6730 (6.9595)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][  3/238]\tBatch time (s)  7.741 ( 7.741)\tIter time (s)  0.968 ( 0.968)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.063 ( 0.063)\tLoss 0.6492 (2.8380)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][  4/238]\tBatch time (s)  7.720 ( 7.720)\tIter time (s)  0.965 ( 0.965)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.063 ( 0.063)\tLoss 0.0830 (0.1622)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][  5/238]\tBatch time (s)  7.804 ( 7.804)\tIter time (s)  0.976 ( 0.976)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.063 ( 0.063)\tLoss 0.0605 (0.0687)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][  6/238]\tBatch time (s)  7.467 ( 7.467)\tIter time (s)  0.933 ( 0.933)\tEpoch time (h)  0.062 ( 0.062)\tRemain time (h)  0.060 ( 0.060)\tLoss 0.0395 (0.0479)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][  7/238]\tBatch time (s)  7.717 ( 7.717)\tIter time (s)  0.965 ( 0.965)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.062 ( 0.062)\tLoss 0.0372 (0.0378)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][  8/238]\tBatch time (s)  7.763 ( 7.763)\tIter time (s)  0.970 ( 0.970)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.062 ( 0.062)\tLoss 0.0327 (0.0371)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][  9/238]\tBatch time (s)  7.742 ( 7.742)\tIter time (s)  0.968 ( 0.968)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.062 ( 0.062)\tLoss 0.0295 (0.0331)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 10/238]\tBatch time (s)  7.761 ( 7.761)\tIter time (s)  0.970 ( 0.970)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.061 ( 0.061)\tLoss 0.0317 (0.0328)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 11/238]\tBatch time (s)  7.437 ( 7.437)\tIter time (s)  0.930 ( 0.930)\tEpoch time (h)  0.061 ( 0.061)\tRemain time (h)  0.059 ( 0.059)\tLoss 0.0289 (0.0297)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 12/238]\tBatch time (s)  7.778 ( 7.778)\tIter time (s)  0.972 ( 0.972)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.061 ( 0.061)\tLoss 0.0286 (0.0285)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 13/238]\tBatch time (s)  7.720 ( 7.720)\tIter time (s)  0.965 ( 0.965)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.060 ( 0.060)\tLoss 0.0270 (0.0278)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 14/238]\tBatch time (s)  7.645 ( 7.645)\tIter time (s)  0.956 ( 0.956)\tEpoch time (h)  0.063 ( 0.063)\tRemain time (h)  0.059 ( 0.059)\tLoss 0.0255 (0.0272)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 15/238]\tBatch time (s)  7.682 ( 7.682)\tIter time (s)  0.960 ( 0.960)\tEpoch time (h)  0.063 ( 0.063)\tRemain time (h)  0.059 ( 0.059)\tLoss 0.0264 (0.0273)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 16/238]\tBatch time (s)  7.428 ( 7.428)\tIter time (s)  0.928 ( 0.928)\tEpoch time (h)  0.061 ( 0.061)\tRemain time (h)  0.057 ( 0.057)\tLoss 0.0237 (0.0263)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 17/238]\tBatch time (s)  7.737 ( 7.737)\tIter time (s)  0.967 ( 0.967)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.059 ( 0.059)\tLoss 0.0248 (0.0249)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 18/238]\tBatch time (s)  7.780 ( 7.780)\tIter time (s)  0.972 ( 0.972)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.059 ( 0.059)\tLoss 0.0238 (0.0235)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 19/238]\tBatch time (s)  7.746 ( 7.746)\tIter time (s)  0.968 ( 0.968)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.059 ( 0.059)\tLoss 0.0224 (0.0222)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 20/238]\tBatch time (s)  7.773 ( 7.773)\tIter time (s)  0.972 ( 0.972)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.059 ( 0.059)\tLoss 0.0225 (0.0225)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 21/238]\tBatch time (s)  7.451 ( 7.451)\tIter time (s)  0.931 ( 0.931)\tEpoch time (h)  0.062 ( 0.062)\tRemain time (h)  0.056 ( 0.056)\tLoss 0.0232 (0.0218)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 22/238]\tBatch time (s)  7.778 ( 7.778)\tIter time (s)  0.972 ( 0.972)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.058 ( 0.058)\tLoss 0.0208 (0.0211)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 23/238]\tBatch time (s)  7.779 ( 7.779)\tIter time (s)  0.972 ( 0.972)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.058 ( 0.058)\tLoss 0.0213 (0.0214)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 24/238]\tBatch time (s)  7.752 ( 7.752)\tIter time (s)  0.969 ( 0.969)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.058 ( 0.058)\tLoss 0.0209 (0.0211)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 25/238]\tBatch time (s)  7.787 ( 7.787)\tIter time (s)  0.973 ( 0.973)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.058 ( 0.058)\tLoss 0.0216 (0.0203)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 26/238]\tBatch time (s)  7.469 ( 7.469)\tIter time (s)  0.934 ( 0.934)\tEpoch time (h)  0.062 ( 0.062)\tRemain time (h)  0.055 ( 0.055)\tLoss 0.0196 (0.0208)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 27/238]\tBatch time (s)  7.795 ( 7.795)\tIter time (s)  0.974 ( 0.974)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.057 ( 0.057)\tLoss 0.0198 (0.0207)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 28/238]\tBatch time (s)  7.812 ( 7.812)\tIter time (s)  0.976 ( 0.976)\tEpoch time (h)  0.065 ( 0.065)\tRemain time (h)  0.057 ( 0.057)\tLoss 0.0196 (0.0207)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 29/238]\tBatch time (s)  7.830 ( 7.830)\tIter time (s)  0.979 ( 0.979)\tEpoch time (h)  0.065 ( 0.065)\tRemain time (h)  0.057 ( 0.057)\tLoss 0.0202 (0.0208)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 30/238]\tBatch time (s) 22.887 (22.887)\tIter time (s)  2.861 ( 2.861)\tEpoch time (h)  0.189 ( 0.189)\tRemain time (h)  0.165 ( 0.165)\tLoss 0.0207 (0.0201)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 31/238]\tBatch time (s)  7.662 ( 7.662)\tIter time (s)  0.958 ( 0.958)\tEpoch time (h)  0.063 ( 0.063)\tRemain time (h)  0.055 ( 0.055)\tLoss 0.0209 (0.0202)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 32/238]\tBatch time (s)  7.784 ( 7.784)\tIter time (s)  0.973 ( 0.973)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.056 ( 0.056)\tLoss 0.0199 (0.0204)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 33/238]\tBatch time (s)  7.804 ( 7.804)\tIter time (s)  0.975 ( 0.975)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.056 ( 0.056)\tLoss 0.0206 (0.0203)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 34/238]\tBatch time (s)  7.779 ( 7.779)\tIter time (s)  0.972 ( 0.972)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.055 ( 0.055)\tLoss 0.0197 (0.0202)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 35/238]\tBatch time (s)  7.796 ( 7.796)\tIter time (s)  0.975 ( 0.975)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.055 ( 0.055)\tLoss 0.0195 (0.0202)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 36/238]\tBatch time (s)  7.447 ( 7.447)\tIter time (s)  0.931 ( 0.931)\tEpoch time (h)  0.062 ( 0.062)\tRemain time (h)  0.052 ( 0.052)\tLoss 0.0203 (0.0204)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 37/238]\tBatch time (s)  7.894 ( 7.894)\tIter time (s)  0.987 ( 0.987)\tEpoch time (h)  0.065 ( 0.065)\tRemain time (h)  0.055 ( 0.055)\tLoss 0.0200 (0.0202)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 38/238]\tBatch time (s)  7.780 ( 7.780)\tIter time (s)  0.973 ( 0.973)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.054 ( 0.054)\tLoss 0.0201 (0.0202)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 39/238]\tBatch time (s)  7.729 ( 7.729)\tIter time (s)  0.966 ( 0.966)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.053 ( 0.053)\tLoss 0.0202 (0.0201)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 40/238]\tBatch time (s)  7.758 ( 7.758)\tIter time (s)  0.970 ( 0.970)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.053 ( 0.053)\tLoss 0.0205 (0.0201)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 41/238]\tBatch time (s)  7.491 ( 7.491)\tIter time (s)  0.936 ( 0.936)\tEpoch time (h)  0.062 ( 0.062)\tRemain time (h)  0.051 ( 0.051)\tLoss 0.0209 (0.0204)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 42/238]\tBatch time (s)  7.750 ( 7.750)\tIter time (s)  0.969 ( 0.969)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.053 ( 0.053)\tLoss 0.0203 (0.0202)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 43/238]\tBatch time (s)  7.741 ( 7.741)\tIter time (s)  0.968 ( 0.968)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.052 ( 0.052)\tLoss 0.0205 (0.0204)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 44/238]\tBatch time (s)  7.742 ( 7.742)\tIter time (s)  0.968 ( 0.968)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.052 ( 0.052)\tLoss 0.0202 (0.0200)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 45/238]\tBatch time (s)  7.786 ( 7.786)\tIter time (s)  0.973 ( 0.973)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.052 ( 0.052)\tLoss 0.0195 (0.0200)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 46/238]\tBatch time (s)  7.451 ( 7.451)\tIter time (s)  0.931 ( 0.931)\tEpoch time (h)  0.062 ( 0.062)\tRemain time (h)  0.050 ( 0.050)\tLoss 0.0203 (0.0201)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 47/238]\tBatch time (s)  7.787 ( 7.787)\tIter time (s)  0.973 ( 0.973)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.052 ( 0.052)\tLoss 0.0200 (0.0199)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 48/238]\tBatch time (s)  7.739 ( 7.739)\tIter time (s)  0.967 ( 0.967)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.051 ( 0.051)\tLoss 0.0200 (0.0202)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 49/238]\tBatch time (s)  7.768 ( 7.768)\tIter time (s)  0.971 ( 0.971)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.051 ( 0.051)\tLoss 0.0207 (0.0204)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 50/238]\tBatch time (s)  7.882 ( 7.882)\tIter time (s)  0.985 ( 0.985)\tEpoch time (h)  0.065 ( 0.065)\tRemain time (h)  0.051 ( 0.051)\tLoss 0.0195 (0.0200)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 51/238]\tBatch time (s)  7.573 ( 7.573)\tIter time (s)  0.947 ( 0.947)\tEpoch time (h)  0.063 ( 0.063)\tRemain time (h)  0.049 ( 0.049)\tLoss 0.0200 (0.0202)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 52/238]\tBatch time (s)  7.814 ( 7.814)\tIter time (s)  0.977 ( 0.977)\tEpoch time (h)  0.065 ( 0.065)\tRemain time (h)  0.050 ( 0.050)\tLoss 0.0202 (0.0201)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 53/238]\tBatch time (s)  7.815 ( 7.815)\tIter time (s)  0.977 ( 0.977)\tEpoch time (h)  0.065 ( 0.065)\tRemain time (h)  0.050 ( 0.050)\tLoss 0.0197 (0.0201)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 54/238]\tBatch time (s)  7.812 ( 7.812)\tIter time (s)  0.977 ( 0.977)\tEpoch time (h)  0.065 ( 0.065)\tRemain time (h)  0.050 ( 0.050)\tLoss 0.0205 (0.0204)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 55/238]\tBatch time (s)  7.808 ( 7.808)\tIter time (s)  0.976 ( 0.976)\tEpoch time (h)  0.065 ( 0.065)\tRemain time (h)  0.050 ( 0.050)\tLoss 0.0204 (0.0204)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 56/238]\tBatch time (s)  7.476 ( 7.476)\tIter time (s)  0.935 ( 0.935)\tEpoch time (h)  0.062 ( 0.062)\tRemain time (h)  0.047 ( 0.047)\tLoss 0.0204 (0.0203)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 57/238]\tBatch time (s)  7.794 ( 7.794)\tIter time (s)  0.974 ( 0.974)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.049 ( 0.049)\tLoss 0.0205 (0.0203)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 58/238]\tBatch time (s)  7.824 ( 7.824)\tIter time (s)  0.978 ( 0.978)\tEpoch time (h)  0.065 ( 0.065)\tRemain time (h)  0.049 ( 0.049)\tLoss 0.0198 (0.0200)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 59/238]\tBatch time (s)  7.844 ( 7.844)\tIter time (s)  0.981 ( 0.981)\tEpoch time (h)  0.065 ( 0.065)\tRemain time (h)  0.049 ( 0.049)\tLoss 0.0201 (0.0202)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 60/238]\tBatch time (s) 23.249 (23.249)\tIter time (s)  2.906 ( 2.906)\tEpoch time (h)  0.192 ( 0.192)\tRemain time (h)  0.144 ( 0.144)\tLoss 0.0201 (0.0201)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 61/238]\tBatch time (s)  7.490 ( 7.490)\tIter time (s)  0.936 ( 0.936)\tEpoch time (h)  0.062 ( 0.062)\tRemain time (h)  0.046 ( 0.046)\tLoss 0.0207 (0.0201)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 62/238]\tBatch time (s)  7.827 ( 7.827)\tIter time (s)  0.978 ( 0.978)\tEpoch time (h)  0.065 ( 0.065)\tRemain time (h)  0.048 ( 0.048)\tLoss 0.0199 (0.0203)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 63/238]\tBatch time (s)  7.837 ( 7.837)\tIter time (s)  0.980 ( 0.980)\tEpoch time (h)  0.065 ( 0.065)\tRemain time (h)  0.048 ( 0.048)\tLoss 0.0195 (0.0201)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 64/238]\tBatch time (s)  7.832 ( 7.832)\tIter time (s)  0.979 ( 0.979)\tEpoch time (h)  0.065 ( 0.065)\tRemain time (h)  0.047 ( 0.047)\tLoss 0.0205 (0.0202)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 65/238]\tBatch time (s)  7.830 ( 7.830)\tIter time (s)  0.979 ( 0.979)\tEpoch time (h)  0.065 ( 0.065)\tRemain time (h)  0.047 ( 0.047)\tLoss 0.0201 (0.0201)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 66/238]\tBatch time (s)  7.478 ( 7.478)\tIter time (s)  0.935 ( 0.935)\tEpoch time (h)  0.062 ( 0.062)\tRemain time (h)  0.045 ( 0.045)\tLoss 0.0202 (0.0202)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 67/238]\tBatch time (s)  7.834 ( 7.834)\tIter time (s)  0.979 ( 0.979)\tEpoch time (h)  0.065 ( 0.065)\tRemain time (h)  0.047 ( 0.047)\tLoss 0.0201 (0.0202)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 68/238]\tBatch time (s)  7.686 ( 7.686)\tIter time (s)  0.961 ( 0.961)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.045 ( 0.045)\tLoss 0.0200 (0.0200)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 69/238]\tBatch time (s)  7.817 ( 7.817)\tIter time (s)  0.977 ( 0.977)\tEpoch time (h)  0.065 ( 0.065)\tRemain time (h)  0.046 ( 0.046)\tLoss 0.0204 (0.0203)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 70/238]\tBatch time (s)  7.906 ( 7.906)\tIter time (s)  0.988 ( 0.988)\tEpoch time (h)  0.065 ( 0.065)\tRemain time (h)  0.046 ( 0.046)\tLoss 0.0200 (0.0204)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 71/238]\tBatch time (s)  7.452 ( 7.452)\tIter time (s)  0.931 ( 0.931)\tEpoch time (h)  0.062 ( 0.062)\tRemain time (h)  0.043 ( 0.043)\tLoss 0.0198 (0.0202)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 72/238]\tBatch time (s)  7.719 ( 7.719)\tIter time (s)  0.965 ( 0.965)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.044 ( 0.044)\tLoss 0.0202 (0.0203)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 73/238]\tBatch time (s)  7.778 ( 7.778)\tIter time (s)  0.972 ( 0.972)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.045 ( 0.045)\tLoss 0.0207 (0.0204)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 74/238]\tBatch time (s)  7.949 ( 7.949)\tIter time (s)  0.994 ( 0.994)\tEpoch time (h)  0.066 ( 0.066)\tRemain time (h)  0.045 ( 0.045)\tLoss 0.0199 (0.0204)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 75/238]\tBatch time (s)  7.697 ( 7.697)\tIter time (s)  0.962 ( 0.962)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.044 ( 0.044)\tLoss 0.0208 (0.0203)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 76/238]\tBatch time (s)  7.331 ( 7.331)\tIter time (s)  0.916 ( 0.916)\tEpoch time (h)  0.061 ( 0.061)\tRemain time (h)  0.041 ( 0.041)\tLoss 0.0196 (0.0203)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 77/238]\tBatch time (s)  7.766 ( 7.766)\tIter time (s)  0.971 ( 0.971)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.043 ( 0.043)\tLoss 0.0205 (0.0202)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 78/238]\tBatch time (s)  7.734 ( 7.734)\tIter time (s)  0.967 ( 0.967)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.043 ( 0.043)\tLoss 0.0198 (0.0201)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 79/238]\tBatch time (s)  7.727 ( 7.727)\tIter time (s)  0.966 ( 0.966)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.043 ( 0.043)\tLoss 0.0203 (0.0202)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 80/238]\tBatch time (s)  7.828 ( 7.828)\tIter time (s)  0.979 ( 0.979)\tEpoch time (h)  0.065 ( 0.065)\tRemain time (h)  0.043 ( 0.043)\tLoss 0.0196 (0.0203)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 81/238]\tBatch time (s)  7.495 ( 7.495)\tIter time (s)  0.937 ( 0.937)\tEpoch time (h)  0.062 ( 0.062)\tRemain time (h)  0.041 ( 0.041)\tLoss 0.0197 (0.0202)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 82/238]\tBatch time (s)  7.737 ( 7.737)\tIter time (s)  0.967 ( 0.967)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.042 ( 0.042)\tLoss 0.0200 (0.0204)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 83/238]\tBatch time (s)  7.772 ( 7.772)\tIter time (s)  0.971 ( 0.971)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.042 ( 0.042)\tLoss 0.0204 (0.0202)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 84/238]\tBatch time (s)  7.762 ( 7.762)\tIter time (s)  0.970 ( 0.970)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.042 ( 0.042)\tLoss 0.0198 (0.0201)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 85/238]\tBatch time (s)  7.749 ( 7.749)\tIter time (s)  0.969 ( 0.969)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.041 ( 0.041)\tLoss 0.0206 (0.0202)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 86/238]\tBatch time (s)  7.469 ( 7.469)\tIter time (s)  0.934 ( 0.934)\tEpoch time (h)  0.062 ( 0.062)\tRemain time (h)  0.039 ( 0.039)\tLoss 0.0194 (0.0202)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 87/238]\tBatch time (s)  7.752 ( 7.752)\tIter time (s)  0.969 ( 0.969)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.041 ( 0.041)\tLoss 0.0202 (0.0206)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 88/238]\tBatch time (s)  7.727 ( 7.727)\tIter time (s)  0.966 ( 0.966)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.040 ( 0.040)\tLoss 0.0206 (0.0201)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 89/238]\tBatch time (s)  7.736 ( 7.736)\tIter time (s)  0.967 ( 0.967)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.040 ( 0.040)\tLoss 0.0197 (0.0200)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 90/238]\tBatch time (s) 22.543 (22.543)\tIter time (s)  2.818 ( 2.818)\tEpoch time (h)  0.186 ( 0.186)\tRemain time (h)  0.116 ( 0.116)\tLoss 0.0199 (0.0201)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 91/238]\tBatch time (s)  7.459 ( 7.459)\tIter time (s)  0.932 ( 0.932)\tEpoch time (h)  0.062 ( 0.062)\tRemain time (h)  0.038 ( 0.038)\tLoss 0.0200 (0.0201)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 92/238]\tBatch time (s)  7.717 ( 7.717)\tIter time (s)  0.965 ( 0.965)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.039 ( 0.039)\tLoss 0.0208 (0.0202)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 93/238]\tBatch time (s)  7.722 ( 7.722)\tIter time (s)  0.965 ( 0.965)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.039 ( 0.039)\tLoss 0.0204 (0.0203)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 94/238]\tBatch time (s)  7.754 ( 7.754)\tIter time (s)  0.969 ( 0.969)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.039 ( 0.039)\tLoss 0.0197 (0.0200)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 95/238]\tBatch time (s)  7.777 ( 7.777)\tIter time (s)  0.972 ( 0.972)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.039 ( 0.039)\tLoss 0.0195 (0.0199)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 96/238]\tBatch time (s)  7.437 ( 7.437)\tIter time (s)  0.930 ( 0.930)\tEpoch time (h)  0.061 ( 0.061)\tRemain time (h)  0.037 ( 0.037)\tLoss 0.0203 (0.0203)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 97/238]\tBatch time (s)  7.737 ( 7.737)\tIter time (s)  0.967 ( 0.967)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.038 ( 0.038)\tLoss 0.0206 (0.0203)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 98/238]\tBatch time (s)  7.743 ( 7.743)\tIter time (s)  0.968 ( 0.968)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.038 ( 0.038)\tLoss 0.0199 (0.0200)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][ 99/238]\tBatch time (s)  7.747 ( 7.747)\tIter time (s)  0.968 ( 0.968)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.037 ( 0.037)\tLoss 0.0201 (0.0202)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][100/238]\tBatch time (s)  7.749 ( 7.749)\tIter time (s)  0.969 ( 0.969)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.037 ( 0.037)\tLoss 0.0206 (0.0206)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][101/238]\tBatch time (s)  7.452 ( 7.452)\tIter time (s)  0.932 ( 0.932)\tEpoch time (h)  0.062 ( 0.062)\tRemain time (h)  0.035 ( 0.035)\tLoss 0.0201 (0.0203)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][102/238]\tBatch time (s)  7.775 ( 7.775)\tIter time (s)  0.972 ( 0.972)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.037 ( 0.037)\tLoss 0.0199 (0.0201)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][103/238]\tBatch time (s)  7.741 ( 7.741)\tIter time (s)  0.968 ( 0.968)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.036 ( 0.036)\tLoss 0.0210 (0.0203)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][104/238]\tBatch time (s)  7.750 ( 7.750)\tIter time (s)  0.969 ( 0.969)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.036 ( 0.036)\tLoss 0.0209 (0.0202)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][105/238]\tBatch time (s)  7.764 ( 7.764)\tIter time (s)  0.971 ( 0.971)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.036 ( 0.036)\tLoss 0.0202 (0.0203)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][106/238]\tBatch time (s)  7.451 ( 7.451)\tIter time (s)  0.931 ( 0.931)\tEpoch time (h)  0.062 ( 0.062)\tRemain time (h)  0.034 ( 0.034)\tLoss 0.0199 (0.0202)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][107/238]\tBatch time (s)  7.756 ( 7.756)\tIter time (s)  0.970 ( 0.970)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.035 ( 0.035)\tLoss 0.0202 (0.0200)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][108/238]\tBatch time (s)  7.812 ( 7.812)\tIter time (s)  0.976 ( 0.976)\tEpoch time (h)  0.065 ( 0.065)\tRemain time (h)  0.035 ( 0.035)\tLoss 0.0200 (0.0202)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][109/238]\tBatch time (s)  7.757 ( 7.757)\tIter time (s)  0.970 ( 0.970)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.035 ( 0.035)\tLoss 0.0202 (0.0201)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][110/238]\tBatch time (s)  7.740 ( 7.740)\tIter time (s)  0.968 ( 0.968)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.034 ( 0.034)\tLoss 0.0201 (0.0204)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][111/238]\tBatch time (s)  7.443 ( 7.443)\tIter time (s)  0.930 ( 0.930)\tEpoch time (h)  0.062 ( 0.062)\tRemain time (h)  0.033 ( 0.033)\tLoss 0.0201 (0.0203)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][112/238]\tBatch time (s)  7.727 ( 7.727)\tIter time (s)  0.966 ( 0.966)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.034 ( 0.034)\tLoss 0.0201 (0.0205)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][113/238]\tBatch time (s)  7.756 ( 7.756)\tIter time (s)  0.969 ( 0.969)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.034 ( 0.034)\tLoss 0.0214 (0.0204)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][114/238]\tBatch time (s)  7.807 ( 7.807)\tIter time (s)  0.976 ( 0.976)\tEpoch time (h)  0.065 ( 0.065)\tRemain time (h)  0.034 ( 0.034)\tLoss 0.0209 (0.0202)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][115/238]\tBatch time (s)  7.843 ( 7.843)\tIter time (s)  0.980 ( 0.980)\tEpoch time (h)  0.065 ( 0.065)\tRemain time (h)  0.033 ( 0.033)\tLoss 0.0208 (0.0202)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][116/238]\tBatch time (s)  7.310 ( 7.310)\tIter time (s)  0.914 ( 0.914)\tEpoch time (h)  0.060 ( 0.060)\tRemain time (h)  0.031 ( 0.031)\tLoss 0.0203 (0.0202)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][117/238]\tBatch time (s)  7.767 ( 7.767)\tIter time (s)  0.971 ( 0.971)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.033 ( 0.033)\tLoss 0.0201 (0.0201)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][118/238]\tBatch time (s)  7.779 ( 7.779)\tIter time (s)  0.972 ( 0.972)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.032 ( 0.032)\tLoss 0.0196 (0.0203)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][119/238]\tBatch time (s)  7.786 ( 7.786)\tIter time (s)  0.973 ( 0.973)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.032 ( 0.032)\tLoss 0.0203 (0.0203)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][120/238]\tBatch time (s) 22.833 (22.833)\tIter time (s)  2.854 ( 2.854)\tEpoch time (h)  0.189 ( 0.189)\tRemain time (h)  0.094 ( 0.094)\tLoss 0.0205 (0.0202)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][121/238]\tBatch time (s)  7.462 ( 7.462)\tIter time (s)  0.933 ( 0.933)\tEpoch time (h)  0.062 ( 0.062)\tRemain time (h)  0.030 ( 0.030)\tLoss 0.0193 (0.0201)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][122/238]\tBatch time (s)  7.763 ( 7.763)\tIter time (s)  0.970 ( 0.970)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.031 ( 0.031)\tLoss 0.0205 (0.0203)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][123/238]\tBatch time (s)  7.802 ( 7.802)\tIter time (s)  0.975 ( 0.975)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.031 ( 0.031)\tLoss 0.0198 (0.0204)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][124/238]\tBatch time (s)  7.763 ( 7.763)\tIter time (s)  0.970 ( 0.970)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.031 ( 0.031)\tLoss 0.0202 (0.0203)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][125/238]\tBatch time (s)  7.804 ( 7.804)\tIter time (s)  0.976 ( 0.976)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.031 ( 0.031)\tLoss 0.0203 (0.0203)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][126/238]\tBatch time (s)  7.474 ( 7.474)\tIter time (s)  0.934 ( 0.934)\tEpoch time (h)  0.062 ( 0.062)\tRemain time (h)  0.029 ( 0.029)\tLoss 0.0202 (0.0201)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][127/238]\tBatch time (s)  7.763 ( 7.763)\tIter time (s)  0.970 ( 0.970)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.030 ( 0.030)\tLoss 0.0201 (0.0203)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][128/238]\tBatch time (s)  7.744 ( 7.744)\tIter time (s)  0.968 ( 0.968)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.030 ( 0.030)\tLoss 0.0201 (0.0201)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][129/238]\tBatch time (s)  7.766 ( 7.766)\tIter time (s)  0.971 ( 0.971)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.029 ( 0.029)\tLoss 0.0205 (0.0203)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][130/238]\tBatch time (s)  7.779 ( 7.779)\tIter time (s)  0.972 ( 0.972)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.029 ( 0.029)\tLoss 0.0202 (0.0200)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][131/238]\tBatch time (s)  7.471 ( 7.471)\tIter time (s)  0.934 ( 0.934)\tEpoch time (h)  0.062 ( 0.062)\tRemain time (h)  0.028 ( 0.028)\tLoss 0.0206 (0.0204)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][132/238]\tBatch time (s)  7.739 ( 7.739)\tIter time (s)  0.967 ( 0.967)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.028 ( 0.028)\tLoss 0.0205 (0.0202)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][133/238]\tBatch time (s)  7.788 ( 7.788)\tIter time (s)  0.973 ( 0.973)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.028 ( 0.028)\tLoss 0.0202 (0.0201)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][134/238]\tBatch time (s)  7.785 ( 7.785)\tIter time (s)  0.973 ( 0.973)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.028 ( 0.028)\tLoss 0.0196 (0.0200)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][135/238]\tBatch time (s)  7.798 ( 7.798)\tIter time (s)  0.975 ( 0.975)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.028 ( 0.028)\tLoss 0.0207 (0.0202)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][136/238]\tBatch time (s)  7.652 ( 7.652)\tIter time (s)  0.957 ( 0.957)\tEpoch time (h)  0.063 ( 0.063)\tRemain time (h)  0.027 ( 0.027)\tLoss 0.0207 (0.0205)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][137/238]\tBatch time (s)  7.753 ( 7.753)\tIter time (s)  0.969 ( 0.969)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.027 ( 0.027)\tLoss 0.0207 (0.0203)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][138/238]\tBatch time (s)  7.741 ( 7.741)\tIter time (s)  0.968 ( 0.968)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.027 ( 0.027)\tLoss 0.0204 (0.0205)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][139/238]\tBatch time (s)  7.755 ( 7.755)\tIter time (s)  0.969 ( 0.969)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.027 ( 0.027)\tLoss 0.0202 (0.0202)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][140/238]\tBatch time (s)  7.772 ( 7.772)\tIter time (s)  0.971 ( 0.971)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.026 ( 0.026)\tLoss 0.0195 (0.0202)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][141/238]\tBatch time (s)  7.476 ( 7.476)\tIter time (s)  0.934 ( 0.934)\tEpoch time (h)  0.062 ( 0.062)\tRemain time (h)  0.025 ( 0.025)\tLoss 0.0202 (0.0204)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][142/238]\tBatch time (s)  7.771 ( 7.771)\tIter time (s)  0.971 ( 0.971)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.026 ( 0.026)\tLoss 0.0205 (0.0203)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][143/238]\tBatch time (s)  7.749 ( 7.749)\tIter time (s)  0.969 ( 0.969)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.026 ( 0.026)\tLoss 0.0200 (0.0202)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][144/238]\tBatch time (s)  7.746 ( 7.746)\tIter time (s)  0.968 ( 0.968)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.025 ( 0.025)\tLoss 0.0206 (0.0202)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][145/238]\tBatch time (s)  7.802 ( 7.802)\tIter time (s)  0.975 ( 0.975)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.025 ( 0.025)\tLoss 0.0202 (0.0200)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][146/238]\tBatch time (s)  7.477 ( 7.477)\tIter time (s)  0.935 ( 0.935)\tEpoch time (h)  0.062 ( 0.062)\tRemain time (h)  0.024 ( 0.024)\tLoss 0.0204 (0.0201)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][147/238]\tBatch time (s)  7.782 ( 7.782)\tIter time (s)  0.973 ( 0.973)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.025 ( 0.025)\tLoss 0.0201 (0.0200)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][148/238]\tBatch time (s)  7.771 ( 7.771)\tIter time (s)  0.971 ( 0.971)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.024 ( 0.024)\tLoss 0.0201 (0.0202)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][149/238]\tBatch time (s) 22.206 (22.206)\tIter time (s)  2.776 ( 2.776)\tEpoch time (h)  0.184 ( 0.184)\tRemain time (h)  0.069 ( 0.069)\tLoss 0.0201 (0.0202)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][150/238]\tBatch time (s)  7.846 ( 7.846)\tIter time (s)  0.981 ( 0.981)\tEpoch time (h)  0.065 ( 0.065)\tRemain time (h)  0.024 ( 0.024)\tLoss 0.0199 (0.0203)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][151/238]\tBatch time (s)  7.501 ( 7.501)\tIter time (s)  0.938 ( 0.938)\tEpoch time (h)  0.062 ( 0.062)\tRemain time (h)  0.023 ( 0.023)\tLoss 0.0196 (0.0205)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][152/238]\tBatch time (s)  7.776 ( 7.776)\tIter time (s)  0.972 ( 0.972)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.023 ( 0.023)\tLoss 0.0200 (0.0201)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][153/238]\tBatch time (s)  7.744 ( 7.744)\tIter time (s)  0.968 ( 0.968)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.023 ( 0.023)\tLoss 0.0195 (0.0201)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][154/238]\tBatch time (s)  7.746 ( 7.746)\tIter time (s)  0.968 ( 0.968)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.023 ( 0.023)\tLoss 0.0193 (0.0200)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][155/238]\tBatch time (s)  7.809 ( 7.809)\tIter time (s)  0.976 ( 0.976)\tEpoch time (h)  0.065 ( 0.065)\tRemain time (h)  0.023 ( 0.023)\tLoss 0.0203 (0.0203)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][156/238]\tBatch time (s)  7.494 ( 7.494)\tIter time (s)  0.937 ( 0.937)\tEpoch time (h)  0.062 ( 0.062)\tRemain time (h)  0.021 ( 0.021)\tLoss 0.0201 (0.0202)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][157/238]\tBatch time (s)  7.738 ( 7.738)\tIter time (s)  0.967 ( 0.967)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.022 ( 0.022)\tLoss 0.0195 (0.0201)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][158/238]\tBatch time (s)  7.767 ( 7.767)\tIter time (s)  0.971 ( 0.971)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.022 ( 0.022)\tLoss 0.0208 (0.0203)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][159/238]\tBatch time (s)  7.804 ( 7.804)\tIter time (s)  0.976 ( 0.976)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.021 ( 0.021)\tLoss 0.0206 (0.0203)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][160/238]\tBatch time (s)  7.761 ( 7.761)\tIter time (s)  0.970 ( 0.970)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.021 ( 0.021)\tLoss 0.0197 (0.0202)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][161/238]\tBatch time (s)  7.456 ( 7.456)\tIter time (s)  0.932 ( 0.932)\tEpoch time (h)  0.062 ( 0.062)\tRemain time (h)  0.020 ( 0.020)\tLoss 0.0206 (0.0204)\tSeq Len 444.000 (444.000)\tCtx Len 152.000 (152.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][162/238]\tBatch time (s)  7.822 ( 7.822)\tIter time (s)  0.978 ( 0.978)\tEpoch time (h)  0.065 ( 0.065)\tRemain time (h)  0.021 ( 0.021)\tLoss 0.0200 (0.0202)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][163/238]\tBatch time (s)  7.806 ( 7.806)\tIter time (s)  0.976 ( 0.976)\tEpoch time (h)  0.065 ( 0.065)\tRemain time (h)  0.020 ( 0.020)\tLoss 0.0200 (0.0202)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n",
      "Epoch: [0][164/238]\tBatch time (s)  7.761 ( 7.761)\tIter time (s)  0.970 ( 0.970)\tEpoch time (h)  0.064 ( 0.064)\tRemain time (h)  0.020 ( 0.020)\tLoss 0.0198 (0.0201)\tSeq Len 443.000 (443.000)\tCtx Len 150.000 (150.000)\tVis Len 736.000 (736.000)\n"
     ]
    }
   ],
   "source": [
    "# 训练ShowUI模型\n",
    "ShowUItrain(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47da84a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并LoRA权重和原始模型\n",
    "ShowUImerge(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4918e3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ShowUI模型推理\n",
    "\n",
    "class ShowUI:\n",
    "    def __init__(self, model_path: str, args):\n",
    "        self.model_path = model_path\n",
    "        self.model = None\n",
    "        self.processor = None\n",
    "        self.args = args\n",
    "\n",
    "    def load_model(self):\n",
    "\n",
    "        torch_dtype = torch.float32\n",
    "        if self.args.precision == \"bf16\":\n",
    "            torch_dtype = torch.bfloat16\n",
    "        elif self.args.precision == \"fp16\":\n",
    "            torch_dtype = torch.half\n",
    "        \n",
    "        print(\"Loading processor...\")\n",
    "        \n",
    "        from model.showui.processing_showui import ShowUIProcessor\n",
    "\n",
    "        self.processor = ShowUIProcessor.from_pretrained(self.args.model_path,\n",
    "                                                min_pixels=self.args.min_visual_tokens *28*28,\n",
    "                                                max_pixels=self.args.max_visual_tokens *28*28,\n",
    "                                                model_max_length=self.args.model_max_length,\n",
    "                                                uigraph_train=self.args.uigraph_train, uigraph_test=self.args.uigraph_test,\n",
    "                                                uigraph_diff=self.args.uigraph_diff,  uigraph_rand=self.args.uigraph_rand,\n",
    "                                                uimask_pre=self.args.uimask_pre, uimask_ratio=self.args.uimask_ratio, uimask_rand=self.args.uimask_rand,\n",
    "                                                size = {\"shortest_edge\": 3136, \"longest_edge\": 1003520}\n",
    "                                              )\n",
    "        \n",
    "        print(\"Processor loaded successfully.\")\n",
    "\n",
    "        print(f\"Loading model from {self.model_path}...\")\n",
    "\n",
    "        bnb_config = BitsAndBytesConfig(\n",
    "                    load_in_4bit=True,\n",
    "                    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                    bnb_4bit_use_double_quant=True,\n",
    "                    bnb_4bit_quant_type=\"nf4\",\n",
    "                    llm_int8_skip_modules=[\"img_projection\"],\n",
    "                ) if self.args.use_qlora else None\n",
    "\n",
    "        from model.utils import parse_layer_type\n",
    "        from model.showui.modeling_showui import ShowUIForConditionalGeneration\n",
    "\n",
    "        lm_qwen_layer = 28\n",
    "        vis_qwen_layer = 32\n",
    "        lm_skip_layer = parse_layer_type(self.args.lm_skip_layer, lm_qwen_layer)\n",
    "        vis_skip_layer = parse_layer_type(self.args.vis_skip_layer, vis_qwen_layer)\n",
    "\n",
    "        self.model = ShowUIForConditionalGeneration.from_pretrained(\n",
    "                                                    self.args.model_path,\n",
    "                                                    torch_dtype=torch_dtype, # 模型精度\n",
    "                                                    low_cpu_mem_usage=True, # 低内存使用模式\n",
    "                                                    _attn_implementation=self.args.attn_imple, # 注意力实现方式\n",
    "                                                    # quantization_config=bnb_config, # 量化配置\n",
    "                                                    device_map=\"cuda\", # 自动设备映射\n",
    "                                                    lm_skip_layer=lm_skip_layer, # 跳过语言层\n",
    "                                                    lm_skip_ratio=self.args.lm_skip_ratio, # 跳过语言层比例\n",
    "    )\n",
    "        \n",
    "        print(\"Model loaded successfully.\")\n",
    "\n",
    "    def invoke(self, img_url: str, query: str, args):\n",
    "        image = Image.open(img_url)\n",
    "\n",
    "        print(f\"Image loaded from {img_url}, size: {image.size}\")\n",
    "        print(f\"Query: {query}\")\n",
    "        \n",
    "\n",
    "        print(\"Processing messages for model input...\")\n",
    "\n",
    "        _SYSTEM = (\n",
    "            \"Based on the screenshot of the page, I give a text description and you give its corresponding location. \"\n",
    "            \"The coordinate represents a clickable location [x, y] for an element, which is a relative coordinate on the screenshot, scaled from 0 to 1.\"\n",
    "        )\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": _SYSTEM},\n",
    "                    {\"type\": \"image\", \"image\": img_url, \"min_pixels\": self.args.min_visual_tokens * 28 * 28, \"max_pixels\": self.args.max_visual_tokens * 28 * 28},\n",
    "                    {\"type\": \"text\", \"text\": query}\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        text = self.processor.apply_chat_template(\n",
    "            messages, tokenize=False, add_generation_prompt=True,\n",
    "        )\n",
    "        image_inputs, video_inputs = process_vision_info(messages)\n",
    "        inputs = self.processor(\n",
    "            text=[text],\n",
    "            images=image_inputs,\n",
    "            videos=video_inputs,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        inputs = inputs.to(\"cuda\")\n",
    "        print(\"Inputs prepared for model generation.\")\n",
    "        generated_ids = self.model.generate(**inputs, max_new_tokens=128)\n",
    "        generated_ids_trimmed = [\n",
    "            out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "        print(\"Model generation completed.\")\n",
    "        print(\"Decoding generated IDs to text...\")\n",
    "        output_text = self.processor.batch_decode(\n",
    "            generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "        )[0]\n",
    "        print(f\"Output text: {output_text}\")\n",
    "        print(\"Decoding completed.\")\n",
    "        \n",
    "        click_xy = ast.literal_eval(output_text)\n",
    "        x, y = click_xy[0] * image.width, click_xy[1] * image.height\n",
    "\n",
    "        \n",
    "        return x, y, image\n",
    "\n",
    "    def draw_point(self, image, x, y, radius=2):\n",
    "        print(f\"Drawing point at ({x}, {y}) with radius {radius} on the image.\")\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        draw.ellipse((x - radius, y - radius, x + radius, y + radius), fill='red', outline='red')\n",
    "        image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dbd28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 ShowUI 实例并加载模型\n",
    "model_path = \"D:/Project/showui-2b\"\n",
    "showui = ShowUI(model_path,args)\n",
    "showui.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bc3700",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_url = \"D:/Project/my_dataset/unlabel_images/image0.png\"\n",
    "query = \"\"\n",
    "\n",
    "x, y, image = showui.invoke(img_url, query, args)\n",
    "print(f\"Click coordinates: ({x}, {y})\")\n",
    "showui.draw_point(image, x, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
