{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb177a52",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4133cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import torch\n",
    "from PIL import Image, ImageDraw\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor, BitsAndBytesConfig\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "class ShowUI:\n",
    "    def __init__(self, model_path: str):\n",
    "        self.model_path = model_path\n",
    "        self.model = None\n",
    "        self.processor = None\n",
    "        self.nf4_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16\n",
    "        )\n",
    "        self.min_pixels = 256*28*28\n",
    "        self.max_pixels = 1344*28*28\n",
    "\n",
    "    def load_model(self):\n",
    "        \n",
    "        print(f\"Loading model from {self.model_path}...\")\n",
    "        \n",
    "        self.model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "            self.model_path,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            device_map=\"auto\",\n",
    "            # quantization_config=self.nf4_config\n",
    "        )\n",
    "        \n",
    "        print(\"Model loaded successfully.\")\n",
    "        \n",
    "        print(\"Loading processor...\")\n",
    "        \n",
    "        self.processor = AutoProcessor.from_pretrained(\n",
    "            self.model_path,\n",
    "            size={\"shortest_edge\": self.min_pixels, \"longest_edge\": self.max_pixels},\n",
    "            use_fast=True\n",
    "        )\n",
    "        \n",
    "        print(\"Processor loaded successfully.\")\n",
    "\n",
    "    def invoke(self, img_url: str, query: str):\n",
    "        image = Image.open(img_url)\n",
    "\n",
    "        print(f\"Image loaded from {img_url}, size: {image.size}\")\n",
    "        print(f\"Query: {query}\")\n",
    "        \n",
    "\n",
    "        print(\"Processing messages for model input...\")\n",
    "\n",
    "        _SYSTEM = (\n",
    "            \"Based on the screenshot of the page, I give a text description and you give its corresponding location. \"\n",
    "            \"The coordinate represents a clickable location [x, y] for an element, which is a relative coordinate on the screenshot, scaled from 0 to 1.\"\n",
    "        )\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": _SYSTEM},\n",
    "                    {\"type\": \"image\", \"image\": img_url, \"min_pixels\": self.min_pixels, \"max_pixels\": self.max_pixels},\n",
    "                    {\"type\": \"text\", \"text\": query}\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        text = self.processor.apply_chat_template(\n",
    "            messages, tokenize=False, add_generation_prompt=True,\n",
    "        )\n",
    "        image_inputs, video_inputs = process_vision_info(messages)\n",
    "        inputs = self.processor(\n",
    "            text=[text],\n",
    "            images=image_inputs,\n",
    "            videos=video_inputs,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        inputs = inputs.to(\"cuda\")\n",
    "        print(\"Inputs prepared for model generation.\")\n",
    "        generated_ids = self.model.generate(**inputs, max_new_tokens=128)\n",
    "        generated_ids_trimmed = [\n",
    "            out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "        print(\"Model generation completed.\")\n",
    "        print(\"Decoding generated IDs to text...\")\n",
    "        output_text = self.processor.batch_decode(\n",
    "            generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "        )[0]\n",
    "        print(f\"Output text: {output_text}\")\n",
    "        print(\"Decoding completed.\")\n",
    "        \n",
    "        click_xy = ast.literal_eval(output_text)\n",
    "        x, y = click_xy[0] * image.width, click_xy[1] * image.height\n",
    "\n",
    "        \n",
    "        return x, y, image\n",
    "\n",
    "    def draw_point(self, image, x, y, radius=2):\n",
    "        print(f\"Drawing point at ({x}, {y}) with radius {radius} on the image.\")\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        draw.ellipse((x - radius, y - radius, x + radius, y + radius), fill='red', outline='red')\n",
    "        image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123d55c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974b7510",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"D:/Project/showui-2b\"\n",
    "    \n",
    "showui = ShowUI(model_path)\n",
    "showui.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c017834",
   "metadata": {},
   "source": [
    "# GUI Navigation\n",
    "## Set up system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7239103",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_url = \"D:/Project/my_dataset/unlabel_images/image0.png\"\n",
    "query = \"重置\"\n",
    "\n",
    "x, y, image = showui.invoke(img_url, query)\n",
    "print(f\"Click coordinates: ({x}, {y})\")\n",
    "showui.draw_point(image, x, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
